{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "adc7f73df85e1bb483876e8b13e01a25",
     "grade": false,
     "grade_id": "cell-8743ac94d9590c18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1 - k-Armed Bandit Problems (32 points)\n",
    "\n",
    "\n",
    "In this assignment, you will implement different strategies (algorithms) to solve k-Armed Bandit problems, and you will compare and visually analyze their relative performance differences. The maximum number of points for each subtask is indicated next to the sections.\n",
    "\n",
    "    \n",
    "Before you start with this problem:\n",
    "- Study the corresponding slide deck(s) and consider re-watching the lecture recording(s).\n",
    "- Internalize the material until you feel confident you can work with them or implement them yourself. Only then start working on this assignment; otherwise, you will waste a lot of time.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Due-Date:** see Moodle\n",
    "   \n",
    "**Constraints**: Operations on SciPy and NumPy arrays only.\n",
    "  \n",
    "**Automatic Grading:** \n",
    "\n",
    "- Replace the placeholders `# YOUR CODE HERE` `raise NotImplementedError()` / `YOUR ANSWER HERE` with your code / answers.\n",
    "- make sure to remove all `raise NotImplementedError()` statements\n",
    "- Put results in the corresponding variable; otherwise, we will not grade your solution (i.e., we assign 0 points).\n",
    "- Do not delete or add cells.\n",
    "    \n",
    "**Submission:** As a ZIP-package via Moodle; the ZIP-package must have the following structure:\n",
    "    \n",
    "    + <student ID, (k + 8 digits), e.g. k01234567>.zip\n",
    "    |\n",
    "    +-- Assignment_<assignment number>.ipynb\n",
    "    +\n",
    "    \n",
    "**Questions?** Post it into the forum!\n",
    "</div>\n",
    "\n",
    "## Running code cells\n",
    "\n",
    "To execute a code cell, use either `Ctrl-Enter`, `Shift-Enter`, or the GUI buttons above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b97413d4bb4684d9d8d80fb25fb45aca",
     "grade": false,
     "grade_id": "cell-95cd9daf99fa9ed8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Definition of the Problem (Repetition)\n",
    "k-armed bandit problem definition:\n",
    "- we repeatedly choose among $k$ different actions\n",
    "- after each action, we receive a numeric reward\n",
    "  (originating from a stationary probability distribution, except in the last exercise in this problem set)\n",
    "- the sole objective: maximize expected total reward over time (by finding and exploiting the most beneficial actions)\n",
    "\n",
    "The particular **algorithm testbed** we will be using here is defined as follows:\n",
    "- a set of 2000 randomly generated $10$-armed bandit problems\n",
    "- for each problem instance, the true action values $q_*(a)$ are sampled from $\\mathcal{N}(0,\\,1)$ in the beginning\n",
    "- the actual rewards $R_t$ are sampled from $\\mathcal{N}(q_*(a),\\,1)$ at each step\n",
    "- we **don't know** the true action values and hence have to **estimate** them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b5f4154cdefeb2c762f2a0b043d3027",
     "grade": false,
     "grade_id": "cell-c58ffe90e6ed1bd8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Python Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2ae9317329a626865d51311a2d8b353",
     "grade": false,
     "grade_id": "cell-acdcb2be4f23ea02",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8290237b639bb7f309dcaafa08d615bf",
     "grade": false,
     "grade_id": "cell-463c7fd574cf87fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Definition of k-Armed Bandit Problem\n",
    "In this section, we implement the actual bandit problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ade078882e78fc6543c8a4367f4061e",
     "grade": false,
     "grade_id": "cell-0aedba8a06dca5eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class kArmedBandit():\n",
    "    \"\"\"\n",
    "    Specifies a k-armed bandit problem\n",
    "    \n",
    "    The agent has to choose from k different actions.\n",
    "    Taking an action yields a numeric reward specified\n",
    "    by a stationary probability distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=10, seed=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            @k: the number of actions / arms / levers of the k-armed bandit\n",
    "            @seed: the seed of the pseudo random number generator (PRNG) that\n",
    "                   completely specifies this (random) k-armed bandit problem.\n",
    "                   if you use 'None' for the seed, numpy will use the entropy\n",
    "                   pool of the operating system to get some true randomness.\n",
    "                   in the interest of having reproducible experiments, we should\n",
    "                   always provide a seed here.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        # sample the true action values from a gaussian\n",
    "        # with mean 0 and standard deviation 1.\n",
    "        \n",
    "        # these are the values we **don't know**!\n",
    "        # we'll never use them directly!\n",
    "        self.q_star = self.rng.normal(0, 1, k)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take one step, choosing 'action'. This is the **only** method\n",
    "        that the agent will interact with.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "           @action: action id (integer in [0, k[)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            the reward for taking this action.\n",
    "        \"\"\"\n",
    "        # the reward is drawn from a normal distribution with\n",
    "        # mean q_star[action] and standard deviation 1\n",
    "        Rt = self.rng.normal(self.q_star[action], 1)\n",
    "        return Rt\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac14e9cc31f5b63afac57ace8ccfe4b5",
     "grade": false,
     "grade_id": "cell-a291b7b0f6b00180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Visualization of one problem instance\n",
    "This section is <b>just for visualizing</b> the problem instances we are facing.\n",
    "For this purpose, we generate one instance of the problem and uniformly select actions to get a notion of the underlying stationary probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08f686bd7ad7325c3ddcbe9677ae30a9",
     "grade": false,
     "grade_id": "cell-d3e7ee6329cab325",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize bandit problem with 10 actions\n",
    "bandit = kArmedBandit(k=10, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b183e552c058801aac87be38ed4bfbd9",
     "grade": false,
     "grade_id": "cell-cd0965cbc969de68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# iterate actions and select each one 1000 times\n",
    "N_SAMPLES = 1000\n",
    "action_rewards = np.zeros((N_SAMPLES, bandit.k))\n",
    "for action in range(bandit.k):\n",
    "    # choose each action several times and recive reward\n",
    "    # (this will (hopefully) reveal the underlying distribution)\n",
    "    for i_sample in range(N_SAMPLES):\n",
    "        reward = bandit.step(action)\n",
    "        action_rewards[i_sample, action] = reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dc9e652a62778667a1d8500d2b4d498",
     "grade": false,
     "grade_id": "cell-3a8da54be26d88ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.violinplot(\n",
    "    action_rewards,\n",
    "    np.arange(0, bandit.k),\n",
    "    showmeans=True,\n",
    "    showmedians=False,\n",
    "    showextrema=True\n",
    ")\n",
    "ax.set_xlabel('action')\n",
    "ax.set_xticks(np.arange(0, bandit.k))\n",
    "ax.set_ylabel('reward distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23482a2a38ddb476368d430728299897",
     "grade": false,
     "grade_id": "cell-ca9b224dab5a63ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Comparison of Standard Algorithms\n",
    "Your task in this exercise is to compare the bandit algorithms listed below on our standard testbed e.g. the 10-armed bandit problem.\n",
    "* Iterative Sample Average Method\n",
    "* Greedy vs. epsilon-Greedy Action Selection\n",
    "* Optimistic Initial Values\n",
    "* Upper Confidence Bound Method\n",
    "* Gradient Bandit Algorithms\n",
    "* Iterative Sample Average Method with constant step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb2bbc1573c867b1c40a9ee21660a11f",
     "grade": false,
     "grade_id": "cell-f849eaf10b9f8f4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Random Action Selection Baseline\n",
    "Implementation of a random action selection baseline. This should just serve as a template for you to implement the \"much more intelligent\" bandit algorithms below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2068f4bc709bd93c0cec71c2379f78c4",
     "grade": false,
     "grade_id": "cell-7745c683a66798fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class RandomBaseline():\n",
    "    def __init__(self, k=10, seed=None):\n",
    "        \"\"\"\n",
    "        Random Action Selection Baseline\n",
    "        \n",
    "        This method simply selects an action at random, and does\n",
    "        not care about rewards at all.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "            @k: number of possible actions (integer)\n",
    "            @seed: PRNG seed\n",
    "        \"\"\"\n",
    "        # we should definitely remember how many actions there are\n",
    "        # in order to make a decision ...\n",
    "        self.k = k\n",
    "        \n",
    "        # all of the random behavior of an agent should depend on a\n",
    "        # PRNG that is initialized in the constructor, given the seed\n",
    "        \n",
    "        # whenever your agent has the need for random numbers,\n",
    "        # you **must use only this** PRNG!\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def choose_action(self):\n",
    "        \"\"\" Action selection is random \"\"\"\n",
    "        # we'll use the PRNG that has been initialized in the constructor\n",
    "        # to draw a uniformly distributed, random integer from the interval [0, k[\n",
    "        return self.rng.integers(0, self.k)\n",
    "    \n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\" Because we behave randomly, we don't need to update anything.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba7605df5623fb3706d430068428e418",
     "grade": false,
     "grade_id": "cell-84559ecbc29c5ffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Experimental setup\n",
    "For comparing the implemented methods, we will create similar <b>time step vs. average reward plots</b> as the ones shown in the lecture slides and the book.\n",
    "\n",
    "In order to facilitate this comparison, we will define a convenience function to run experiments. This enables us to specify an `agent_class` together with its parameters `agent_args` and then run `n_runs` different instances of the k-armed bandit problem for `n_steps` steps, using `agent_class` to solve the problems.\n",
    "\n",
    "\n",
    "**Hint:** for debugging purposes, you may want to run a smaller number of runs for a smaller number of steps; to do so, you may change `n_runs` and `n_steps` when calling the function, but ...\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "\n",
    "    \n",
    "<b>Please remember to change them back to `n_runs=2000` and `n_steps=1000`, and re-run the entire notebook before submitting!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(exp_seed,\n",
    "                    n_runs=2000,\n",
    "                    n_steps=1000,\n",
    "                    k=10,\n",
    "                    bandit_class=kArmedBandit,\n",
    "                    agent_class=RandomBaseline,\n",
    "                    agent_args=dict()):\n",
    "    \"\"\"\n",
    "    Run experiments following the policy of the provided agent.\n",
    "    is\n",
    "    Parameters\n",
    "    ----------\n",
    "    @exp_seed: the seed for the 'mother-PRNG' that produces all other seeds\n",
    "    @n_runs: number of different bandit problems (integer)\n",
    "             (to debug your algorithms, you may set this to a lower number.\n",
    "              don't forget to change it back, once you're done with debugging!)\n",
    "    @n_steps: number of steps taken in each individual problem (integer)\n",
    "              (to debug your algorithms, you may set this to a lower number.\n",
    "              don't forget to change it back, once you're done with debugging!)\n",
    "    @k: number of actions for the bandit problems (integer)\n",
    "    @bandit_class: this allows you to change the type of bandit\n",
    "                   (please only do so for the last problem in this problem set)\n",
    "    @agent_class: specifies the bandit algorithm to use\n",
    "    @agent_args: this dictionary of arguments will be passed on\n",
    "                 to the constructor of the specified bandit algorithm,\n",
    "                 \n",
    "                 (with the exception of 'k' and 'seed', as these will be set\n",
    "                 by the experiment loop)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array of rewards with shape (n_runs, n_steps), where\n",
    "    element (i,j) contains the reward in the i-th run, on the j-th step\n",
    "    \"\"\"\n",
    "    # n_runs=1\n",
    "    # n_steps=1000\n",
    "    \n",
    "    args_list = [f'{key}={val}' for key, val in sorted(agent_args.items())]\n",
    "    args_string = ','.join(args_list)\n",
    "    print(\"running {}({})\".format(agent_class.__name__, args_string))\n",
    "    \n",
    "    # initialize results\n",
    "    rewards = np.zeros((n_runs, n_steps))\n",
    "\n",
    "    if isinstance(exp_seed, list):\n",
    "        exp_seed = exp_seed[0]\n",
    "    \n",
    "    # if we're getting entropy, initialize new seed sequence\n",
    "    if isinstance(exp_seed, int):\n",
    "        exp_seed_sequence = np.random.SeedSequence(exp_seed)\n",
    "    elif isinstance(exp_seed, np.random.SeedSequence):\n",
    "        exp_seed_sequence = exp_seed\n",
    "    else:\n",
    "        raise ValueError('please provide SeedSequence or int!')\n",
    "    \n",
    "    # perform multiple runs\n",
    "    for run in range(n_runs):\n",
    "        # split off 2 new seeds, one for the agent, one for the bandit\n",
    "        agent_seed, bandit_seed = exp_seed_sequence.spawn(2)\n",
    "\n",
    "        # instantiate agent, pass it its arguments\n",
    "        agent = agent_class(k=k, seed=agent_seed, **agent_args)\n",
    "        \n",
    "        # get new instance of problem, with new seed\n",
    "        bandit = bandit_class(k=k, seed=bandit_seed)\n",
    "\n",
    "        # perform multiple steps on problem instance\n",
    "        for step in range(n_steps):\n",
    "\n",
    "            # let the agent pick an action according to its selection strategy\n",
    "            action = agent.choose_action()\n",
    "\n",
    "            # the bandit is told the action that the agent chose, and gives out a reward\n",
    "            reward = bandit.step(action)\n",
    "\n",
    "            # the agent is told what the reward was for choosing the action\n",
    "            agent.update_estimates(action, reward)\n",
    "\n",
    "            # we will record all rewards for later analysis\n",
    "            rewards[run, step] = reward\n",
    "    \n",
    "    print(\"done!\")\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6df8bdbd311288c517b71716fa7bfa3a",
     "grade": false,
     "grade_id": "cell-34b33d6be46b2be8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Example Experiments, Random Action Selection\n",
    "Lets see how well our random action selection baseline performs, and run one experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3548bea1b5cbdf9a59a3f5af637aa455",
     "grade": false,
     "grade_id": "cell-0bfe5b41216ddd98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "rewards_random = run_experiments(exp_seed=1234, agent_class=RandomBaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4bdfeda4f096afb0c1ca867f6b3ea7f",
     "grade": false,
     "grade_id": "cell-e08a69e672cdfe3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    rewards_random.mean(axis=0),  # average over all runs\n",
    "    label='random baseline'       # choose a name\n",
    ")\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "ax.set_title(\"Random Action Selection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "483e7741fae7305eb8378870843c8bea",
     "grade": false,
     "grade_id": "cell-ac8e14733e5e24b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Run multiple example experiments, collect results\n",
    "Let's see how we can run multiple experiments, with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6e6283f4400e28d39aea637a9060c74",
     "grade": false,
     "grade_id": "cell-2ad10da809cb7d8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for consecutive experiments, having a so-called 'seed sequence', is\n",
    "# extremely convenient. also look it up in the documentation, to see\n",
    "# why this is a \"really good idea(tm)\"!\n",
    "exp_seed_sequence = np.random.SeedSequence(4711)\n",
    "\n",
    "# it's convenient to store the experiments in a\n",
    "# dictionary, so we can iterate over them more easily later on\n",
    "all_rewards = dict()\n",
    "all_rewards['algo A, params X, Y, ...'] = run_experiments(\n",
    "    exp_seed=exp_seed_sequence,\n",
    "    agent_class=RandomBaseline\n",
    ")\n",
    "all_rewards['algo B, params U, V, ...'] = run_experiments(\n",
    "    exp_seed=exp_seed_sequence,\n",
    "    agent_class=RandomBaseline\n",
    ")\n",
    "\n",
    "# (the algorithms in this example have the same parameters\n",
    "# but b/c they're completely random anyways, it does not matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6183b7e3b8378e8360db45bf1d1a894c",
     "grade": false,
     "grade_id": "cell-36bdad49956dc678",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize multiple results in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8bbeff0e2dada43fc6766d7ff37888e",
     "grade": false,
     "grade_id": "cell-89b75b81a66a7925",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over axis=0, meaning 'over all runs'\n",
    "        label=label\n",
    "    )\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dab92fbd89da577d32061d4be15c314",
     "grade": false,
     "grade_id": "cell-efa13fb9fdb1ba56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## 1.1 Incremental Sample Average Method (5 points)\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "Implementation of the Sample Average Method (ISAM). The algorithm is parametrized by the number of actions and a probability $\\epsilon$ of picking a random action instead of following the policy. Use the optional parameter `initial_value` to implement the \"Optimistic Initial Values\" trick that encourages exploration.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18a4b4490c72813e7cb1ab9a7722ca2f",
     "grade": false,
     "grade_id": "cell-e513c97050bfe84a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class IncrementalSampleAverageMethod():\n",
    "    def __init__(self, k=10, epsilon=0.0, initial_value=0.0, seed=None):\n",
    "        \"\"\"\n",
    "        Incremental Implementation of the \"Sample Average Method\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            @k: number of possible actions (integer)\n",
    "            @epsilon: probability for selecting a random action (float in the interval [0, 1])\n",
    "            @initial_value: initial action value estimate (should be used for Optimistic Initial Values)\n",
    "            @seed: the PRNG seed. the PRNG will help us to decide when to explore and when to exploit\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # initialize an array with our initial estimates\n",
    "        self.Q = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # initialize an array with the action counts\n",
    "        self.N = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # seed the PRNG\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\" Action selection \"\"\"\n",
    "        action = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return action\n",
    "    \n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\" Update action value estimate \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8151fc08c7342799b94baaaa761ae9a2",
     "grade": true,
     "grade_id": "cell-6060e9faedac07ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "isam = IncrementalSampleAverageMethod()\n",
    "\n",
    "assert isam.Q is not None, \"estimates are not initialized\"\n",
    "assert isam.N is not None, \"action counts are not initialized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba4a81430a0a23063787222da80e5c3a",
     "grade": true,
     "grade_id": "cell-af1d308f0b033eb0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "isam = IncrementalSampleAverageMethod()\n",
    "\n",
    "assert isam.choose_action() is not None, \"choose_action not implemented!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8a6749a508944ad679c1cf51a2a5d1b",
     "grade": true,
     "grade_id": "cell-1aa4a1c905c8d33a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc793050ee431e63a763e3f2c6a4a745",
     "grade": false,
     "grade_id": "cell-f80dcc5257597d22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.2 Greedy vs. $\\epsilon$-Greedy (6 points)\n",
    "\n",
    "In our first experiment, we will explore the influence of the random action selection probability $\\epsilon$ on the average reward we get over time.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "For this purpose:\n",
    "<br> - run the *IncrementalSampleAverageMethod* (ISAM) three times with $\\epsilon \\in \\{0.0, 0.01, 0.1\\}$.\n",
    "<br> - collect the rewards that could be achieved for each parametrization, and plot their means in one plot for comparison.\n",
    "<br> - answer the questions below\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c9a7d9f6c829143b81e7924c33b970b",
     "grade": false,
     "grade_id": "cell-c5f2f97b99a98b82",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "epsilons = [0., 0.01, 0.1]\n",
    "exp_seed_sequence = np.random.SeedSequence(1234)\n",
    "\n",
    "# store the reward squences into this dictionary\n",
    "all_rewards = {\n",
    "    'ISAM (purely greedy)': None,\n",
    "    'ISAM (epsilon = 0.01)': None,\n",
    "    'ISAM (epsilon = 0.1)': None\n",
    "}\n",
    "\n",
    "# use run_experiments to collect the rewards\n",
    "# run help(run_experiments) to see the function's parameters\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63822a51da290064f0ddee94af37f1d3",
     "grade": true,
     "grade_id": "cell-f92d6dccb4887903",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in all_rewards.items()]), \"Store the reward squences into the all rewards dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcaf8e6a2069b546a7e031787eb53832",
     "grade": false,
     "grade_id": "cell-922954945d30fe17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over all runs\n",
    "        label=label\n",
    "    )\n",
    "ax.set_ylim([0.0, 1.6])\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "307279390ee99711d3dc986db02fc64d",
     "grade": false,
     "grade_id": "cell-ed8f5dffe13ae031",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Answer the following questions:\n",
    "- Which method will perform best in the long run? (in terms of cumulative reward and the probability of selecting the optimal action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9936e64e0eff12724103a4ff37a8561",
     "grade": false,
     "grade_id": "cell-468ba6127eab308b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# select one answer by uncommenting one of the answers (don't forget to remove the error statement)\n",
    "best_method = None\n",
    "#best_method = 'ISAM (purely greedy)'\n",
    "#best_method = 'ISAM (epsilon = 0.01)'\n",
    "#best_method = 'ISAM (epsilon = 0.1)'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fe2b5792d5a037705d9a7cf89385037",
     "grade": true,
     "grade_id": "cell-e8d45212e6c5ca20",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert best_method is not None, 'Uncomment the correct answer!'\n",
    "assert best_method in ['ISAM (purely greedy)', 'ISAM (epsilon = 0.01)', 'ISAM (epsilon = 0.1)'], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73c71b048bd513057c2de839dc007ead",
     "grade": false,
     "grade_id": "cell-d1690c2e4e3d6f26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- On average, how often will 'ISAM ($\\epsilon = 0.01$)' select the greedy move if $k=10$, i.e., what is the probability of a greedy action if $\\epsilon=0.01$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3decca38c4f8ce549b3b5109096ab6d5",
     "grade": false,
     "grade_id": "cell-6227b86b17551704",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store the result into this variable (don't forget to remove the error statement)\n",
    "p_greedy = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d52d57e309da489f3350a58a384f100",
     "grade": true,
     "grade_id": "cell-9b52bfc426b25539",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 0 <= p_greedy and p_greedy <= 1, 'Probabilities must be inbetween 0 and 1.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c502687f232911a505de344b71323c2f",
     "grade": false,
     "grade_id": "cell-e5dc8d0c3237632c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is the following statement correct?\n",
    "\n",
    "- The estimated values $Q(a)$ do not converge to the true values $q_*(a)$ because $\\epsilon$-greedy action selection behaves randomly from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5826b15b8de0eec7d5e54d3d9154d32",
     "grade": false,
     "grade_id": "cell-2108b004693d72b0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "values_do_not_converge_to_true_values = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e015ccc1e505fd01d7cfc07f9850a3c0",
     "grade": true,
     "grade_id": "cell-8649e8666bde64cd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert values_do_not_converge_to_true_values is not None, 'Store True/ False!'\n",
    "assert values_do_not_converge_to_true_values in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d690c6ab1b75cd27aa98547180a2e4cd",
     "grade": false,
     "grade_id": "cell-fd2d0262098d2518",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is the following statement correct?\n",
    "- If $q_*(a) > q_*(b)$ for all actions $b \\neq a$, then action $a$ will be the greedy action in the long run (asymptotically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a65a6836fc52af4f1c0471211b09d1c0",
     "grade": false,
     "grade_id": "cell-dd552160a1329b8e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "if_true_value_is_largest_then_action_a_is_greedy = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2af6b8d9920660234fb6830a396397e1",
     "grade": true,
     "grade_id": "cell-8b012f2c8da907d9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert if_true_value_is_largest_then_action_a_is_greedy is not None, 'Store True/ False!'\n",
    "assert if_true_value_is_largest_then_action_a_is_greedy in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a14d41b286e717bbfbaf8a9e45ab8e6",
     "grade": false,
     "grade_id": "cell-c37ceb209a6fb053",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is the following statement correct?\n",
    "- A setting $\\epsilon$ to a larger value will result in a lower average reward (asymptotically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3ca184c94bc6c2f405543fa7c548921",
     "grade": false,
     "grade_id": "cell-bd3bf3141a03c227",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "higher_epsilon_means_low_reward_and_slow_convergence = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b643272498a5636ce1ec4eb71f1b408d",
     "grade": true,
     "grade_id": "cell-059e0faf2e9e8e84",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert higher_epsilon_means_low_reward_and_slow_convergence is not None, 'Store True/ False!'\n",
    "assert higher_epsilon_means_low_reward_and_slow_convergence in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47238d0334049df8235b6f1aa7d768ce",
     "grade": false,
     "grade_id": "cell-603651936d7bfc21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1.3 Greedy vs. Optimistic Initial Values (2 points)\n",
    "In our second experiment, we evaluate the performance of another approach to encourage exploration, namely Optimistic Initial Values.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "For this purpose\n",
    "<br>- run *IncrementalSampleAverageMethod* with an initial value of $5$ for all actions and $\\epsilon=0$\n",
    "<br>- and compare its performance with the *IncrementalSampleAverageMethod* with an initial value of $0$ and $\\epsilon=0$\n",
    "<br>- finally, answer the following questions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca772087f89081849095880196c24302",
     "grade": false,
     "grade_id": "cell-a8ea27c1950a9c6a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "exp_seed_sequence = np.random.SeedSequence(1234)\n",
    "\n",
    "all_rewards = {\n",
    "    'ISAM (purely greedy)': None,\n",
    "    'OIV(initial_value=5)': None\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60ade85bd755ce0443806ec8e7b5e985",
     "grade": true,
     "grade_id": "cell-e6e4f98e448dc252",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in all_rewards.items()]), \"Store the reward squences into the all rewards dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58104bc16b657ddbd79ed73a0e2ec353",
     "grade": false,
     "grade_id": "cell-253f7e0e73a78513",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over all runs\n",
    "        label=label\n",
    "    )\n",
    "ax.set_ylim([0.0, 1.6])\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1c9218f1467355b8b1b3f0735ea5b7e",
     "grade": false,
     "grade_id": "cell-e1647d34ce77299d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is the following statement correct?\n",
    "- OIV-method ($\\epsilon=0$) will perform fewer and fewer exploratory moves because the initial bias of the estimated values decreases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78a98a1c217758664a748b91ef9510ed",
     "grade": false,
     "grade_id": "cell-e0ee32826d0c7e0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "fewer_exporatory_moves_bc_bias_vanishes = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "961e5e86e814aefe7109a0536d5c7259",
     "grade": true,
     "grade_id": "cell-1c61df958bcbdbad",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert fewer_exporatory_moves_bc_bias_vanishes is not None, 'Store True/ False!'\n",
    "assert fewer_exporatory_moves_bc_bias_vanishes in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4456c9de17c354f9a28570f9e46b891f",
     "grade": false,
     "grade_id": "cell-7456269140df6dac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Upper Confidence Bound Action Selection (5 points)\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "Implement the Upper Confidence Bound Action Selection Method. The algorithm is parametrized by the number of actions and a value $c > 0$ to control the degree of exploration. \n",
    "</div>\n",
    "\n",
    "**Important**: In case of multiple occurrences of the maximum values, the indices corresponding to the first occurrence must be returned (default behaviour of `np.argmax`).\n",
    "\n",
    "**Hint:** In case you encounter a division by 0 error, take a closer look at the values for $t$ and $N_t(a)$.\n",
    "Note that if $N_t(a) = 0$, then $a$ is considererd to be a greedy (maximizing) action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0bf9ecfd1c9d985d2f8be71c98b0cb3",
     "grade": false,
     "grade_id": "cell-0621591de1e55918",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class UpperConfidenceBound():\n",
    "    def __init__(self, k=10, c=0.0, seed=None):\n",
    "        \"\"\"\n",
    "        Upper Confidence Bound Action Selection Method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            @k: number of possible actions (integer)\n",
    "            @c: parameter that trades off exploration and exploitation\n",
    "            @seed: for this algorithm, this does not do anything, but it needs\n",
    "                   to be there, b/c all other constructors have this ...\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "                \n",
    "        # initialize value function estimates to zero\n",
    "        self.Q = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # initialize action counter\n",
    "        self.N = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\" Action selection \"\"\"\n",
    "        At = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return At\n",
    "    \n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\" Update counter and action value estimate \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccd0f371e2cc425801a6ed07128381d1",
     "grade": true,
     "grade_id": "cell-f6dd6741ff38d0a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ucb = UpperConfidenceBound()\n",
    "\n",
    "assert ucb.Q is not None, \"value function not initialized\"\n",
    "assert ucb.N is not None, \"action counter not initialized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0726c148a1befd91469c0fac07aaab7",
     "grade": true,
     "grade_id": "cell-9ceaa8d786e73b7c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ucb = UpperConfidenceBound()\n",
    "\n",
    "assert ucb.choose_action() is not None, \"choose_action not implemented!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf0477ba2adb6fce68fc354c18e23eec",
     "grade": true,
     "grade_id": "cell-99d0ea426f6f23ee",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "beb8bbcfe71bceff041a486999494680",
     "grade": false,
     "grade_id": "cell-ebf2664e70bc24c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 2.2 $\\epsilon$-Greedy vs Upper Confidence Bound Action Selection (2 points)\n",
    "In our next experiment we compare $\\epsilon$-greedy action selection with the *UCB* action selection algorithm.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "For this purpose:\n",
    "<br>- run the *UCB* action selection algorithm with exploration parameter $c=2$\n",
    "<br>- and compare its performance with the *IncrementalSampleAverageMethod* and $\\epsilon=0.1$\n",
    "<br>- answer the following questions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d62b6e03971a4f8113d06d889144dc96",
     "grade": false,
     "grade_id": "cell-1172d67d366a37e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "exp_seed_sequence = np.random.SeedSequence(1234)\n",
    "\n",
    "# run experiments\n",
    "all_rewards = {\n",
    "    '$\\epsilon$ = 0.1': None,\n",
    "    'UCB(c=2)': None\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39ec125079e3600d4e1914071369524f",
     "grade": true,
     "grade_id": "cell-dc695773e29216d3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in all_rewards.items()]), \"Store the reward squences into the all rewards dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2a373bc315bee2a1c1bca54c8f747ac",
     "grade": false,
     "grade_id": "cell-85348210b8024ca9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over all runs\n",
    "        label=label\n",
    "    )\n",
    "ax.set_ylim([0.0, 1.6])\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d96d83a697b635f4b9de4c58e572b25",
     "grade": false,
     "grade_id": "cell-7da8259265d33309",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The previous figure shows a distinct spike of UCB (orange) at step 11.\n",
    "\n",
    "Is the following statement correct?\n",
    "-  This spike would be less prominent if a lower value was chosen for $c$, e.g., $c=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2acc24bc23eefa42da83590dbf6d1956",
     "grade": false,
     "grade_id": "cell-4821c5191be8c0df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "UCB_spike = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa3d2531492b62613f967e2c45318e06",
     "grade": true,
     "grade_id": "cell-b9dda1ea55f13791",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert UCB_spike is not None, 'Store True/ False!'\n",
    "assert UCB_spike in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ee5ee1537c4b56ef239d971d4cff137",
     "grade": false,
     "grade_id": "cell-df9cf7f59d481203",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.1 Gradient Bandit Algorithm (5 points)\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "Implement the Gradient Bandit Algorithm with baseline. The algorithm is parametrized by the number of actions and step size $\\alpha$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "208b0bd3a4cad7cde825fb95aa798e00",
     "grade": false,
     "grade_id": "cell-209b9d3d4105c5a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GradientBandit():\n",
    "    def __init__(self, k=10, alpha=0.1, seed=None):\n",
    "        \"\"\"\n",
    "        Gradient Bandit Action Selection Method\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            @k: number of possible actions (integer)\n",
    "            @alpha: step-size parameter, or learn rate (float)\n",
    "            @seed: the PRNG seed. it'll be used to sample from the softmax distribution.\n",
    "        \"\"\" \n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "        # initialize action selection preferences, baseline and step\n",
    "        self.H = None\n",
    "        self.baseline = None\n",
    "        self.step = None\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\" Action selection \"\"\"\n",
    "        # choose action according to preference\n",
    "        At = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return At\n",
    "    \n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\" update step count and action selection preferences \"\"\"\n",
    "        # update baseline and\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ef3e18bb29a721328bd504c9ef636e2",
     "grade": true,
     "grade_id": "cell-90e3fdf1ee0d5274",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gb = GradientBandit()\n",
    "\n",
    "assert gb.H is not None, \"prferences not initialized\"\n",
    "assert gb.baseline is not None, \"baseline not initialized\"\n",
    "assert gb.step is not None, \"step not initialized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dc87046834b7b6380193f81455234d3",
     "grade": true,
     "grade_id": "cell-d5be1acddf648982",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gb = GradientBandit()\n",
    "\n",
    "assert gb.choose_action() is not None, \"choose_action not implemented!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d85503ddbd2a4fc586c039382659af4a",
     "grade": true,
     "grade_id": "cell-9309b8b82d74e623",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d34fcad24994a42f4b2e8ff5a5e79bda",
     "grade": false,
     "grade_id": "cell-bded7533a0153f1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.2 $\\epsilon$-Greedy vs Gradient Bandit (2 points)\n",
    "In our last experiment we compare $\\epsilon$-greedy action selection with the *GradientBandit* algorithm.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "For this purpose:\n",
    "<br>- run the *GradientBandit* algorithm with step sizes $\\alpha=0.01$ and $0.1$.\n",
    "<br>- and compare its performance with the *IncrementalSampleAverageMethod* and $\\epsilon=0.1$.\n",
    "<br>- answer the following question\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "673c1a9506c9206c37eee30f6a144624",
     "grade": false,
     "grade_id": "cell-c9f7536f0b3972c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "exp_seed_sequence = np.random.SeedSequence(1234)\n",
    "\n",
    "all_rewards = {\n",
    "    'GB(alpha = 0.01)': None,\n",
    "    'GB(alpha = 0.1)': None,\n",
    "    'ISAM(epsilon = 0.1)': None\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61e9d92928ed5e3a46d66ce932b6dcc8",
     "grade": true,
     "grade_id": "cell-ae7c141149c74dd3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in all_rewards.items()]), \"Store the reward squences into the all rewards dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ae8f62569dd54500a92f2fc210fdb4d",
     "grade": false,
     "grade_id": "cell-118992928a9e4cb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over all runs\n",
    "        label=label\n",
    "    )\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92f3a09903587e49baa85e05e98faf94",
     "grade": false,
     "grade_id": "cell-ca0637c30699fc97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is the following statement correct?\n",
    "- Action selection preferences (H) have no interpretation in terms of reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79f9f6f5ad9b65da601b403d7d554438",
     "grade": false,
     "grade_id": "cell-494a26d7f407b16a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True or False\n",
    "gradient_bandit_action_selection_preferences = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91921636b86b432cac56a7fc014dcf99",
     "grade": true,
     "grade_id": "cell-5a942056e374a8a3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert gradient_bandit_action_selection_preferences is not None, 'Store True/ False!'\n",
    "assert gradient_bandit_action_selection_preferences in [True, False], 'Invalid answer!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb49027ff7a9795388967b48a5cfd464",
     "grade": false,
     "grade_id": "cell-3f340c0f184c2a8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 4. Tracking non-stationary problems (5 points)\n",
    "Sample-average methods have difficulties with <b>non-stationary</b> problems. We will use a <b>modified</b> version of the 10-armed bandit, in which all the $q_{\\star}(a)$ start out equal and then take independent random walks. This is implemented already below.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "You just need to create a <b>modified version</b> of the Incremental Sample Average Method that is able to deal with non-stationary problems.\n",
    "\n",
    "You will need to run separate experiments for:\n",
    "- an action-value method using sample averages, incrementally computed by $\\alpha=\\frac{1}{n}$ (you have that already)\n",
    "- another action-value method that uses a constant step-size parameter, $\\alpha=0.1$ (you still need to create that)\n",
    "\n",
    "Use an $\\epsilon=0.1$ for both methods, and then briefly describe the behavior of the two algorithms.\n",
    "\n",
    "(this is very similar to Exercise 2.5 from the book)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a462e0f432e9c8835aa24bdc975782cd",
     "grade": false,
     "grade_id": "cell-0d465756e060de9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NonstationaryKArmedBandit():\n",
    "    def __init__(self, k=10, seed=None):\n",
    "        self.k = k\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        # for the non-stationary bandit problem, all true action\n",
    "        # values will start out equal\n",
    "        self.q_star = np.zeros(k)\n",
    "    \n",
    "    def step(self, action):\n",
    "        # but the true value will move around randomly this time\n",
    "        self.q_star += self.rng.normal(0, 0.01, self.k)\n",
    "        Rt = self.rng.normal(self.q_star[action], 1)\n",
    "        return Rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e801a1e56b27bd2425737fd3101f9f71",
     "grade": false,
     "grade_id": "cell-1ad35c558934e21a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ISAM_cs():\n",
    "    def __init__(self, k=10, epsilon=0.0, initial_value=0.0, alpha=0.1, seed=None):\n",
    "        self.k = k\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # initialize an array with our initial estimates\n",
    "        self.Q = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # seed the PRNG\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        \n",
    "    def choose_action(self):\n",
    "        \"\"\" Action selection \"\"\"\n",
    "        action = None\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return action\n",
    "    \n",
    "    def update_estimates(self, action, reward):\n",
    "        \"\"\" Update action value estimate \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdb5277743457c75ce263717d56f9354",
     "grade": true,
     "grade_id": "cell-e6d77ffb8b2d207b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "isam_cs = ISAM_cs()\n",
    "\n",
    "assert isam_cs.Q is not None, \"value function not initialized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4198dcd16ca00e212ede60d01b48834c",
     "grade": true,
     "grade_id": "cell-9f136b76d182aa2d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "isam_cs = ISAM_cs()\n",
    "\n",
    "assert isam_cs.choose_action() is not None, \"choose_action is not implemented!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cccbe011eda9c423d58680cc73479b6",
     "grade": true,
     "grade_id": "cell-16980fa2da14e35c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca46d32daccbb55c146c0079bea03cfb",
     "grade": false,
     "grade_id": "cell-d3481c5767ca8411",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# run experiments\n",
    "exp_seed_sequence = np.random.SeedSequence(4711)\n",
    "\n",
    "all_rewards = {\n",
    "    'ISAM(epsilon=0.1)': None,\n",
    "    'ISAM_cs(epsilon=0.1)': None\n",
    "    \n",
    "}\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b9207d25803649ce2b274123780437",
     "grade": true,
     "grade_id": "cell-ae7c58353c8de5e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in all_rewards.items()]), \"Store the reward squences into the all rewards dictionary.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffbd138b8d2bd7828a2c7b5d385bf8b0",
     "grade": false,
     "grade_id": "cell-4b9b700f215e8c59",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, rewards in all_rewards.items():\n",
    "    ax.plot(\n",
    "        rewards.mean(axis=0),  # average over all runs\n",
    "        label=label\n",
    "    )\n",
    "# ax.set_ylim([0.0, 1.6])\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel(\"Average Reward\")\n",
    "ax.set_xlabel(\"Step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53e8576d093bfa493dce12a223b1c86d",
     "grade": false,
     "grade_id": "cell-7881fde9ac3e9e88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Anser the following Question:\n",
    "- Which of the implemented methods are suitable for non-stationary problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b668d437f60104947b50f4f0782033c",
     "grade": false,
     "grade_id": "cell-0ce458353c8de5e3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# store True/ False for each item in the dictionary and remove the raise error statement\n",
    "suitable_for_nonstationary_problems = {\n",
    "    'ISAM': None,\n",
    "    'ISAM_with_constant_alpha': None,\n",
    "    'UCB': None,\n",
    "    'OIV': None\n",
    "}\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dfb18267f512686aeab562976caa496",
     "grade": true,
     "grade_id": "cell-163d0278de6f2ba7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert all([r is not None for i, r in suitable_for_nonstationary_problems.items()]), \"Store True or False for each item in the dictionary!\"\n",
    "assert all([r in [True, False] for i, r in suitable_for_nonstationary_problems.items()]), \"Store True or False for each item in the dictionary!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reex",
   "language": "python",
   "name": "reex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
