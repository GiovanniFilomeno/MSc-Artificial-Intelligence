{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37947954259d35f2fcf85ce5dea0c65",
     "grade": false,
     "grade_id": "cell-d6e49c0f3b2294e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bayesian_network import BayesNet\n",
    "from utils import sample_forward, get_default_bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f12d6681c911844a780baf4557356f3",
     "grade": false,
     "grade_id": "cell-cbf36ef06ad975a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Parameter Learning\n",
    "\n",
    "In this problem, we will assume that a fixed dependency graph structure between variables is given and learn the parameters (the complete Conditional Probability Distribution Table (CPDT)) from a set of events. Furthermore, we will use log-likelihood to find a model structure that also generalizes to future data.\n",
    "    \n",
    "## ML Estimates for Conditional Distributions\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>maximum_likelihood_estimate</i> function, which computes the Maximum Likelihood Estimate for the parameters of a discrete (conditional) probability distribution $ P(X \\mid \\mathit{pa}(X) )$, given a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`maximum_likelihood_estimate` takes  three parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `variable_id` is the column index of the variable to estimate the distribution for.\n",
    "- `parent_ids` is a tuple, containing the column indices of parent variables.\n",
    "- `alpha` is a non-negative integer, corresponding to pseudocounts in Laplace smoothing.\n",
    "\n",
    "`maximum_likelihood_estimate` must return one object:\n",
    "- A Maximum Likelihood Estimate (MLE) of the parameters in form of a `np.ndarray`. The first dimension (index `0`) of the returned array must correspond to variable `variable_id`, the remaining dimensions must be sorted according to `parent_ids`. Altogether, tuple `(variable_id, ) + parent_ids` gives the mapping of dimensions to variables.\n",
    "\n",
    "Hint:\n",
    "- Assume that all variables are boolean.\n",
    "- To count elements in a Numpy array, you simply loop over the data array.\n",
    "- The smoothing parameter `alpha` is added to the counts of each possible event represented in the CPDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e93fc8cd23615080625ca14bbff79e",
     "grade": false,
     "grade_id": "cell-436ef56fc07b775c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_estimate(data: np.ndarray, variable_id: int, parent_ids: tuple=tuple(), alpha: int=0):\n",
    "    \"\"\"\n",
    "    Estimates the conditional probability distribution of a (discrete) variable from data.\n",
    "    :param data:    data to estimate distribution from\n",
    "    :param variable_id:  column index corresponding to the variable we estimate the distribution for\n",
    "    :param parent_ids: column indices of the variables the distribution is conditioned on\n",
    "    :param alpha: smoothing parameter, pseudocounts\n",
    "    :returns: estimated conditional probability distribution table\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(variable_id) == int\n",
    "    assert type(parent_ids) == tuple\n",
    "    \n",
    "    # mapping of axis to variable_id,\n",
    "    # e.g. the variable with id variable_ids[i] is on axis i of the CPDT\n",
    "    variable_ids = (variable_id,) + parent_ids\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    num_parents = len(parent_ids)\n",
    "    shape = (2,) * (1+num_parents)\n",
    "\n",
    "    counts = np.zeros(shape, dtype=np.float64)\n",
    "\n",
    "    variable_data = data[:, variable_id]\n",
    "\n",
    "    if num_parents > 0:\n",
    "        parent_data = data[:, parent_ids]\n",
    "        indices = (variable_data,) + tuple(parent_data[:, i] for i in range(num_parents))\n",
    "    else:\n",
    "        indices = (variable_data,)\n",
    "    \n",
    "    np.add.at(counts, indices, 1)\n",
    "\n",
    "    counts += alpha\n",
    "    \n",
    "    parent_counts = counts.sum(axis=0, keepdims=True)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        cpdt = counts / parent_counts\n",
    "        cpdt = np.nan_to_num(cpdt)\n",
    "            \n",
    "    return cpdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e64485165c8633ae69c633bd1e3edc8a",
     "grade": true,
     "grade_id": "cell-1c8f099373bf6fc1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# get exact A form bayes net\n",
    "expected = bayes_net[_A_].pdt[:,0,0,0,0]\n",
    "# estimate A from the data\n",
    "actual = maximum_likelihood_estimate(data, _A_)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# get exact B_A form bayes net\n",
    "expected = bayes_net[_B_].pdt[:,:,0,0,0].T\n",
    "# estimate B_A from data\n",
    "actual = maximum_likelihood_estimate(data, _B_, (_A_,))\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# test if alpha correctly added\n",
    "expected = [0.29166667, 0.70833333]\n",
    "# estimate A from the data with alpha=10\n",
    "actual = maximum_likelihood_estimate(data, _A_, alpha=10)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cedffdc1886efc3d1407de536e6c4db6",
     "grade": false,
     "grade_id": "cell-266284793d5b1fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Log-Likelihood Function\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>log_likelihood</i> function, which computes the log-likelihood $\\mathcal{L}(\\mathcal{M} : \\mathcal{D})$ of a model (BayesNet) relative to a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`log_likelihood` takes two parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `bayes_net` a BayesNet object representing the model $\\mathcal{M}$ (containing already estimated CPDTs).\n",
    "\n",
    "`log_likelihood` must return one object:\n",
    "- The log-likelihood of the model given the data (i.e., a floating point number (<= 0)).\n",
    "\n",
    "Hint:\n",
    "- Recall that iterating over the variables in the BayesNet is super easy: `for variable in bayes_net: ...`.\n",
    "- The probability distribution of variable $X$ given its parents $\\mathit{pa}(X)$, $P(X \\mid \\mathit{pa}(X))$, can be obtained by passing the random event to the variable, i.e., `variable(data[i])`.\n",
    "- Use the natural logarithm for your computations, i.e. `np.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee480429f8e2cb73da6c99354ff29bc6",
     "grade": false,
     "grade_id": "cell-05bb2766b425e4ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(data: np.ndarray, bayes_net: BayesNet):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of a given Bayesian network relative to the data.\n",
    "    :param data: data to compute the log-likelihood relative to.\n",
    "    :param bayes_net: Bayesian network model.\n",
    "    :returns: the log-likelihood of the Bayesian network relative to the data.\n",
    "    \"\"\"    \n",
    "\n",
    "    ll = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = data[i]\n",
    "        \n",
    "        for variable in bayes_net:\n",
    "            x_i = sample[variable.id]\n",
    "            prob_distribution = variable(sample)\n",
    "            prob = prob_distribution[x_i]\n",
    "            \n",
    "            if prob > 0:\n",
    "                ll += np.log(prob)\n",
    "            else:\n",
    "                return -np.inf\n",
    "    \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10cb46e7d0cb2b0175e85aeabbfefbe7",
     "grade": true,
     "grade_id": "cell-fb8f52c535549516",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# expected log-likelihood\n",
    "expected = -215.9\n",
    "# actual log-likelihood\n",
    "actual = log_likelihood(data, bayes_net)\n",
    "\n",
    "# must be close\n",
    "assert np.all(np.isclose(expected, actual, atol=0.1))\n",
    "\n",
    "\n",
    "# remove unused variables\n",
    "del data\n",
    "del bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da19792956cd8484de125e18621651c2",
     "grade": false,
     "grade_id": "cell-46024e03394db093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding a Model for Strokes   \n",
    "\n",
    "After watching hours of medical dramas on television, you try to figure out the perfect prediction model for strokes. Some of your computer science colleagues told you about how Bayesian networks can be used for symptom diagnosis, so you decide to model your ideas using this technique. \n",
    "\n",
    "Let's assume that you magically know the true underlying Bayes model (structure and parameters); all variables in this example are boolean (false=0 or true=1).  \n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod2.svg\">\n",
    "\n",
    "The conditional probability tables are given as follows:\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>-</td><td>0.01</td><td>0.99</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(H | A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>$h_0$</td><td>0.9</td><td>0.8</td></tr><tr><td>$h_1$</td><td>0.1</td><td>0.2</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(S | H)</th><th>$h_0$<br></th><th>$h_1$</th></tr><tr><td>$s_0$</td><td>0.9</td><td>0.85</td></tr><tr><td>$s_1$</td><td>0.1</td><td>0.15</td></tr></table>\n",
    "\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th rowspan=\"2\">P(C | A, S)</th><th colspan=\"2\">$a_0$<br></th><th colspan=\"2\">$a_1$</th></tr><tr><td>$s_0$</td><td>$s_1$</td><td>$s_0$</td><td>$s_1$</td></tr><tr><td>$c_0$<br></td><td>0.8</td><td>0.7</td><td>0.85</td><td>0.45</td></tr><tr><td>$c_1$</td><td>0.2</td><td>0.3</td><td>0.15</td><td>0.55</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(V | S)</th><th>$s_0$</th><th>$s_1$</th></tr><tr><td>$v_0$</td><td>0.1</td><td>0.2</td></tr><tr><td>$v_1$</td><td>0.9</td><td>0.8</td></tr></table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7f49c7805956098e38a9b9b94c56929",
     "grade": false,
     "grade_id": "cell-2e0a9f7bef60a27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to find a good model, you would need to collect a lot of training examples.\n",
    "\n",
    "But since we know the true undelying model, you can instead just sample 5000 events from this network as the training data, and 5000 samples as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0a771d23aaec82b53deb33258d4ea82",
     "grade": false,
     "grade_id": "cell-4c0f9e2cac1e27af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "A = np.array([0.01, 0.99])\n",
    "H_A = np.array([[0.9, 0.8], [0.1, 0.2]])\n",
    "S_H = np.array([[0.9, 0.85], [0.1, 0.15]])\n",
    "C_AS = np.array([[[0.8, 0.7], [0.85, 0.45]], [[0.2, 0.3], [0.15, 0.55]]])\n",
    "V_S = np.array([[0.1, 0.2], [0.9, 0.8]])\n",
    "\n",
    "# this bayes net represents the true underlying full joint distribution in the medical world \n",
    "true_bayes_net = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "np.random.seed(0)\n",
    "train = sample_forward(true_bayes_net, 5000)\n",
    "test = sample_forward(true_bayes_net, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459c15ec9089733c14868e31c0435cfe",
     "grade": false,
     "grade_id": "cell-461bf6d16acbfa3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for the true underlying network structure and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "  \n",
    "  \n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34703c76c2900f4125d1e0b31852e752",
     "grade": false,
     "grade_id": "cell-adce166a4d080cf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_log_likelihood_1: -8508.579282438383\n"
     ]
    }
   ],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_H, C_AS, V_S = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "A = maximum_likelihood_estimate(train, variable_id=_A_, parent_ids=(), alpha=0)\n",
    "H_A = maximum_likelihood_estimate(train, variable_id=_H_, parent_ids=(_A_,), alpha=0)\n",
    "S_H = maximum_likelihood_estimate(train, variable_id=_S_, parent_ids=(_H_,), alpha=0)\n",
    "C_AS = maximum_likelihood_estimate(train, variable_id=_C_, parent_ids=(_A_, _S_), alpha=0)\n",
    "V_S = maximum_likelihood_estimate(train, variable_id=_V_, parent_ids=(_S_,), alpha=0)\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_S.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_1 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_1 = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "tr_log_likelihood_1 = log_likelihood(train, bayes_net_1)\n",
    "\n",
    "print('tr_log_likelihood_1:', tr_log_likelihood_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "918dcd10a1ae90d0bc22830499e3de6e",
     "grade": true,
     "grade_id": "cell-aee49c763a9fe1a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_1 < -8500\n",
    "assert tr_log_likelihood_1 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2393bddc509932735cd176b77944eca1",
     "grade": false,
     "grade_id": "cell-262f7422251f2622",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Back to our strokes model: Having no idea of the true underlying network structure, you decide to try out the following very simple model first:\n",
    "    \n",
    "<img style='width:100%;  max-width:400px;' src=\"img/bn_mod1.svg\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e419893d0128bfe05a9abe6e7415328",
     "grade": false,
     "grade_id": "cell-11b996647bc6f74c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_log_likelihood_2 -8740.033479010004\n"
     ]
    }
   ],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H, S, C, V = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "A = maximum_likelihood_estimate(train, variable_id=_A_, parent_ids=(), alpha=0)\n",
    "H = maximum_likelihood_estimate(train, variable_id=_H_, parent_ids=(), alpha=0)\n",
    "S = maximum_likelihood_estimate(train, variable_id=_S_, parent_ids=(), alpha=0)\n",
    "C = maximum_likelihood_estimate(train, variable_id=_C_, parent_ids=(), alpha=0)\n",
    "V = maximum_likelihood_estimate(train, variable_id=_V_, parent_ids=(), alpha=0)\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_2 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H, (_H_,)),\n",
    "    (S, (_S_,)),\n",
    "    (C, (_C_,)),\n",
    "    (V, (_V_,))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_2 = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "tr_log_likelihood_2 = log_likelihood(train, bayes_net_2)\n",
    "\n",
    "print('tr_log_likelihood_2', tr_log_likelihood_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b8bd563930aaaadc2b9083539df8a8",
     "grade": true,
     "grade_id": "cell-b30990c4827845f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_2 < -8500\n",
    "assert tr_log_likelihood_2 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0c6ae1d70483dc96759881859f8a634",
     "grade": false,
     "grade_id": "cell-d0193730bdfc314d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Unhappy with the result, you decide to try out a second, more complex model:\n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod3.svg\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36794cfa03210bd015bb0528213caa23",
     "grade": false,
     "grade_id": "cell-385934a752ed9259",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_log_likelihood_3 -8504.427454360399\n"
     ]
    }
   ],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_AH, C_AS, V_CS = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "A = maximum_likelihood_estimate(train, variable_id=_A_, parent_ids=(), alpha=0)\n",
    "H_A = maximum_likelihood_estimate(train, variable_id=_H_, parent_ids=(_A_,), alpha=0)\n",
    "S_AH = maximum_likelihood_estimate(train, variable_id=_S_, parent_ids=(_A_, _H_), alpha=0)\n",
    "C_AS = maximum_likelihood_estimate(train, variable_id=_C_, parent_ids=(_A_, _S_), alpha=0)\n",
    "V_CS = maximum_likelihood_estimate(train, variable_id=_V_, parent_ids=(_C_, _S_), alpha=0)\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_AH.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_CS.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_3 = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "tr_log_likelihood_3 = log_likelihood(train, bayes_net_3)\n",
    "\n",
    "print('tr_log_likelihood_3', tr_log_likelihood_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0745ab2383ea7481c0124edd4c68cd3a",
     "grade": true,
     "grade_id": "cell-0847b76132961219",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_3 < -8500\n",
    "assert tr_log_likelihood_3 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4a47de1161e05ec4d2536c5891e5d90",
     "grade": false,
     "grade_id": "cell-60eaec1dda1e7b09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Train Log-Likelihoods\n",
    "\n",
    "Compare the log-likelihoods w.r.t the training data of Model **M1** (having the true underlying structure) to the two new models (**M2** - no edges, **M3** - complex model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae46f32357d5c58a722e4046bf08c6f0",
     "grade": false,
     "grade_id": "cell-14898c94ac010e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(train|M1) = -8508.579282438383\n",
      "logP(train|M2) = -8740.033479010004\n",
      "logP(train|M3) = -8504.427454360399\n"
     ]
    }
   ],
   "source": [
    "print('logP(train|M1) = {}'.format(tr_log_likelihood_1))\n",
    "print('logP(train|M2) = {}'.format(tr_log_likelihood_2))\n",
    "print('logP(train|M3) = {}'.format(tr_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f3d168c63f1925ef3830ddedcb83a1d",
     "grade": false,
     "grade_id": "cell-c6cc8633bf6db812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question in one sentence! (1 point)\n",
    "</div>\n",
    "\n",
    "Even though **M1** has the true underlying network structure (it correctly represents all independencies holding in our world), it doesn't have the highest train log-likelihood. How do you explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be344344394f67f5fe02c21d744f98f0",
     "grade": true,
     "grade_id": "cell-f239713a903eec15",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Because M3 goes to overfit under the training data (due to higher number of parameters) and that's why achieves highest log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd2f2499bbbce42c077b6faffd9e5b08",
     "grade": false,
     "grade_id": "cell-913efb638a138834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Test Log-Likelihoods\n",
    "\n",
    "Finally, we compute the test log-likelihood of the model **M1** (having the true underlying structure) and the newly created models **M2** and **M3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2d838d52c5ec2698eecbf58224ce14",
     "grade": false,
     "grade_id": "cell-7405d51a161fef12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(test|M1) = -8376.49246068484\n",
      "logP(test|M2) = -8598.449646741903\n",
      "logP(test|M3) = -8379.468463963516\n"
     ]
    }
   ],
   "source": [
    "te_log_likelihood_1 = log_likelihood(test, bayes_net_1)\n",
    "te_log_likelihood_2 = log_likelihood(test, bayes_net_2)\n",
    "te_log_likelihood_3 = log_likelihood(test, bayes_net_3)\n",
    "\n",
    "print('logP(test|M1) = {}'.format(te_log_likelihood_1))\n",
    "print('logP(test|M2) = {}'.format(te_log_likelihood_2))\n",
    "print('logP(test|M3) = {}'.format(te_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b3f8f0b7221f84f4b0e4dc5838584bc",
     "grade": false,
     "grade_id": "cell-305b267f209685e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answers short! (1 point)\n",
    "</div>\n",
    "\n",
    "What is the difference compared the the log-likelihoods of the training data? Explain the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d059bd7ea2f45258367e174a11b3d48c",
     "grade": true,
     "grade_id": "cell-b53213b16dfb15f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "In this case, M1 achieves a higher log-likelihood because it generalizes better to unseen data since it is the true model. On the contrary, since M3 ofertis the training data, it does not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3be3187cdfc89852d5ccdf4d24b89eb3",
     "grade": false,
     "grade_id": "cell-513dda62c8ee6d5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Laplace Smoothing\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answer short! (1 point)\n",
    "</div>\n",
    "\n",
    "Estimate the (conditional) probability tables for your model **M3** again. However, this time you only have a training set consisting of 100 samples. You run into the error shown in the output of the code cell below. Explain the source of the problem and how to avoid it by adapting a parameter when calling the function ```maximum_likelihood_estimate```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52567a2a99156b1ec48da9aa7d140464",
     "grade": true,
     "grade_id": "cell-256e320984be291c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Due to the low number of training samples, some combinations of variables have zero counts. For this reason, the cpdt cannot sum to 1 along axis 0, which is a violation of the BayesNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Probabilities on axis 0 have to sum to 1!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m C_AS \u001b[38;5;241m=\u001b[39m maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n\u001b[1;32m      9\u001b[0m V_CS \u001b[38;5;241m=\u001b[39m maximum_likelihood_estimate(train, _V_, (_S_,_C_,))\n\u001b[0;32m---> 11\u001b[0m bayes_net_3 \u001b[38;5;241m=\u001b[39m BayesNet(\n\u001b[1;32m     12\u001b[0m     (A, (_A_,)),\n\u001b[1;32m     13\u001b[0m     (H_A, (_H_,_A_)),\n\u001b[1;32m     14\u001b[0m     (S_AH, (_S_,_A_,_H_)),\n\u001b[1;32m     15\u001b[0m     (C_AS, (_C_,_A_,_S_)),\n\u001b[1;32m     16\u001b[0m     (V_CS, (_V_,_C_,_S_))\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Probabilistic model/k12315325/bayesian_network.py:120\u001b[0m, in \u001b[0;36mBayesNet.__init__\u001b[0;34m(self, resampling_distribution, *pdt_ids_tuples)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(structure)\u001b[38;5;241m.\u001b[39missubset(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_nodes))), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid node ID in table descriptor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Node IDs must be in range(num_nodes) ( < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pdt_ids_tuples)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Tuple: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdt,\u001b[38;5;250m \u001b[39mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(pdt) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability Density Table has to be a NumPy ndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    119\u001b[0m                                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but was of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pdt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misclose(pdt\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbabilities on axis 0 have to sum to 1!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pdt\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    122\u001b[0m     structure), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of table dimensions has to match \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    123\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe number of Variable indices (1 (self) + n_parents)!\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    124\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN-Dimensions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdt\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != Len(Idcs): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(structure)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Order PDT dimensions by variable id\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Probabilities on axis 0 have to sum to 1!"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# we generate a new training set consisting of 100 samples\n",
    "train = sample_forward(true_bayes_net, 100)  \n",
    "\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H_A = maximum_likelihood_estimate(train, _H_, (_A_,))\n",
    "S_AH = maximum_likelihood_estimate(train, _S_, (_A_, _H_,))\n",
    "C_AS = maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n",
    "V_CS = maximum_likelihood_estimate(train, _V_, (_S_,_C_,))\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
