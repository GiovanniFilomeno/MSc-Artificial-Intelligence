{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80b19f3d70fb214ddd481e1dcd954c8e",
     "grade": false,
     "grade_id": "cell-f57ba107dc3ee0f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Refresh your knowledge of the provided classes *BayesNet* and *Variable* by reading the `BayesNet Introduction` notebook** before you start working on this problem set!\n",
    "</div>\n",
    "\n",
    "# Gibbs Sampling & Parameter Learning\n",
    "## Problem Set 3 \n",
    "\n",
    "## Probabilistic Models UE\n",
    "\n",
    "---\n",
    "In the third assignment, you will familiarise yourself with Gibbs sampling, estimate the (conditional) probability tables (i.e., parameters) of a given network structure from data, and compare the performance of different models in terms of log-likelihood.\n",
    "\n",
    "## Submission\n",
    "\n",
    "**Due-Date:** see Moodle\n",
    " \n",
    "**Automatic Grading:** \n",
    "\n",
    "- Replace the placeholders `# YOUR CODE HERE` `raise NotImplementedError()` / `YOUR ANSWER HERE` with your code / answers.\n",
    "- Put results in the corresponding variable; otherwise, we will not grade your solution (i.e., we assign 0 points).\n",
    "- Do not delete or add cells.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "**Submission:** As a ZIP-package via Moodle; the ZIP-package **must have the following structure**:\n",
    "    \n",
    "    <student ID, (k + 8 digits), e.g. k01234567>.zip\n",
    "    +-- Problem_1.ipynb\n",
    "    |-- Problem_2.ipynb\n",
    "    |-- Supplementary Materials (optional)\n",
    "    + \n",
    "\n",
    "**Questions?** Post them into the Problem Set Forum!        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ffdb374537744995e24d5d7ead5b7aa",
     "grade": false,
     "grade_id": "cell-93a25d73c760b3dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bayesian_network import BayesNet, Variable\n",
    "from utils import sample_categorical, sample_lw, get_default_bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef6320237f77954ba5218362e8dcb2bc",
     "grade": false,
     "grade_id": "cell-22454d3cc82de6a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Gibbs Sampling\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Implement the Gibbs sampling algorithm and use it to approximate $P(A \\mid D, E)$.\n",
    "</div>\n",
    "\n",
    "In Gibbs sampling, we sample directly from the target distribution $P_{\\mathcal{B}}( \\mathbf{Y} \\mid \\mathbf{E}=\\mathbf{e})$ ($\\mathbf{Y}$ denotes the set of non-evidence variables). We do this by implicitly constructing a sequence of proposal distributions that converge to the target distribution.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Implement\n",
    "- `resampling_distribution`,\n",
    "- `sample_gibbs`, and\n",
    "- `gibbs_sampling`.\n",
    "\n",
    "`resampling_distribution` computes the re-sampling distribution for a given variable.\n",
    "\n",
    "`sample_gibbs` samples a sequence of random events according to all the relevant re-sampling distributions. \n",
    "\n",
    "`gibbs_sampling` approximates $P( X \\mid \\mathbf{E}=\\mathbf{e})$ from a sequence of random events. Again, we will only consider probabilistic queries with one query variable $X$.\n",
    "\n",
    "### Pre-computing the Re-sampling Distribution\n",
    "\n",
    "\n",
    "Before we implement the Gibbs sampling algorithm, let us first write a helper function, which pre-computes the re-sampling distribution $P(X \\mid mb(X))$ for an arbitrary variable $X$ in a given Bayesian Network.\n",
    "\n",
    "Consider the following Bayesian network:\n",
    "\n",
    "<img width='30%' src='img/bn.svg'>\n",
    "\n",
    "To pre-compute $P(B \\mid mb(B)) = P(B \\mid A, C, D)$, we only need the conditional distribution of the $B$ and all of B's children, i.e., $P(B \\mid A)$ and $P(D \\mid B, C)$\n",
    "\n",
    "\n",
    "<img width='30%' src='img/mb.png'>\n",
    "\n",
    "\n",
    "The re-sampling distribution of $B$ can then be computed as follows: $P(B \\mid A, C, D) = \\frac{P(B \\mid A) \\cdot P(D \\mid B, C)}{\\sum_{b \\in val(B)} P(B=b \\mid A) \\cdot P(D \\mid B=b, C)}$\n",
    "\n",
    "As an example, let's compute the re-sampling distribution for $B$ with NumPy. First, let us create the bayes net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93dd696e3ed1ed4f6bf614a79853863e",
     "grade": false,
     "grade_id": "cell-58b823716104508c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize the Bayes net\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A = np.array([0.2, 0.8])\n",
    "B_A = np.array([[0.9, 0.2], [0.1, 0.8]])\n",
    "C = np.array([0.9, 0.1])\n",
    "D_BC = np.array([[[0.1, 0.2], [0.99, 0.8]], [[0.9, 0.8], [0.01, 0.2]]])\n",
    "E_C = np.array([[0.7, 0.4], [0.3, 0.6]])\n",
    "            \n",
    "bayes_net = BayesNet(\n",
    "    (A, [_A_]),\n",
    "    (B_A, [_B_, _A_]),\n",
    "    (C, [_C_]),\n",
    "    (D_BC, [_D_, _B_, _C_]),\n",
    "    (E_C, [_E_, _C_])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a05864f0225be7e361b3cd6c2b238889",
     "grade": false,
     "grade_id": "cell-8712f6a224f45f16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can use the (conditional) probability distribution table of each variable (`variable.pdt`) to compute the re-sampling distribution. Note that the axes of `variable.pdt` are sorted by the variables's IDs and singleton dimensions are inserted for non-parent variables. This will make computations easier b/c we don't have to swap dimensions or insert empty dimensions for broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72d58ffcc257ec011cbf299990c8ad4a",
     "grade": false,
     "grade_id": "cell-1897c98f4ee3961e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Shape of P(B | A):    ', bayes_net[_B_].pdt.shape)\n",
    "print('Shape of P(D | B, C): ', bayes_net[_D_].pdt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "676fdbed8f11db2f054fea1c3213f1f4",
     "grade": false,
     "grade_id": "cell-6188fd84040d49c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Computing $P(B \\mid A, C, D) = \\frac{P(B \\mid A) \\cdot P(D \\mid B, C)}{\\sum_{b \\in val(B)} P(B=b \\mid A) \\cdot P(D \\mid B=b, C)}$ is then easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06e55d8641be33d46765ff6361b2e830",
     "grade": false,
     "grade_id": "cell-30a0567a9ffc1831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute the rdt\n",
    "\n",
    "rdt = bayes_net[_B_].pdt * bayes_net[_D_].pdt \n",
    "rdt = rdt / rdt.sum(axis=_B_, keepdims=True)\n",
    "\n",
    "print(rdt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e2eb7e3e41cb5946be81652bf963079",
     "grade": false,
     "grade_id": "cell-c34706b6bdbfe4a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The dimensions of the re-sampling distribution table are also sorted by variable id, and singleton dimensions of size 1 are inserted for non-Markov-blanket variables. This is also the expected output format of the *resampling_distribution* function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa5ec5e8a4a57cbd6046ca710bc363e9",
     "grade": false,
     "grade_id": "cell-1cc43b62830671a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Pre-computing All the Re-sampling Distributions\n",
    "\n",
    "The `BayesNet` class has an optional constructor argument that have not used so far. This argument takes a function that computes the re-sampling distribution for a given variable. If this is provided, the `BayesNet` will use it to pre-compute re-sampling distribution tables for all its variables upon construction. These will become useful when we implement Gibbs sampling.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>resampling_distribution</i> function, which computes the re-sampling distribution for a given variable. (4 points)\n",
    "</div>\n",
    "\n",
    "`resampling_distribution` takes two parameters:\n",
    "- `variable` is a `Variable` object for which the re-sampling distribution is to be computed.\n",
    "- `bayes_net` is a `BayesNet` object which holds the (conditional) probability distribution table of each variable.\n",
    "\n",
    "`resampling_distribution` returns a tuple containing two objects:\n",
    "- a `np.ndarray` containing the re-sampling distribution $P(X \\mid \\textit{mb}(X))$ of the variable. The dimensions of the re-sampling distribution table must be sorted by variable id, and singleton dimensions of size 1 must be inserted for non-Markov-blanket variables.\n",
    "- a `set` containing the IDs of all variables in $\\textit{mb}(X)$. \n",
    "\n",
    "Hints:\n",
    " - `variable.parents` and `variable.children` will give you the ids of all parent and child variables, respectively.\n",
    " - `bayes_net[i]` returns the variable object with id `i`\n",
    " - `variable.pdt` gives the conditional probability distribution table of variable given its parents. The axis of this table are sorted by variable id, and singleton dimensions of size 1 are inserted for parent variables.\n",
    " - use `mb.add` or `mb.union` to add new variables to the `set`\n",
    " - use `mb.remove` or `mb.difference` to remove variables from the `set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72c3df7a4a596652584f68b4163c8b49",
     "grade": false,
     "grade_id": "cell-464a86a09df9563f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def resampling_distribution(variable: Variable, bayes_net: BayesNet):\n",
    "    '''\n",
    "    Computes the resampling distribution given a variable and a Bayesian network.\n",
    "    :param variable: The variable for which to compute the resampling distribution.\n",
    "    :param bayes_net: A Bayesian network of type BayesNet. The bayes net is used to obtain the\n",
    "                      probability table from child variables.\n",
    "    :returns: A tuple containing the resampling distribution ('rdt') and a list containing\n",
    "              the IDs of variables in the Markov blanket ('mb').\n",
    "    '''\n",
    "    \n",
    "    rdt, mb = None, None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    assert rdt.ndim == len(bayes_net)\n",
    "    assert variable.id not in mb\n",
    "    assert type(mb) is set\n",
    "    \n",
    "    return rdt, mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b421d004a1d92195405684d692fe9c7",
     "grade": true,
     "grade_id": "cell-6d645eda5b831e05",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get_default_bayes_net returns the same Bayes net as defined above; just in case the variable was modified...\n",
    "bayes_net = get_default_bayes_net()\n",
    "\n",
    "# compute resampling distribution table of P( B | mb(B) ); same as above \n",
    "rdt = bayes_net[_D_].pdt * bayes_net[_B_].pdt\n",
    "rdt = rdt / rdt.sum(axis=_B_, keepdims=True)\n",
    "# set containing all the indices of the variables in mb(B)\n",
    "mb = {_A_, _D_, _C_}\n",
    "\n",
    "expected = rdt, mb\n",
    "actual = resampling_distribution(bayes_net[_B_], bayes_net)\n",
    "\n",
    "#sanity checks\n",
    "assert type(actual[1]) == type(expected[1]), f'Set of parents has wrong data type.\\n Expected: {type(expected[1])}\\nGiven: {type(actual[1])}'\n",
    "assert actual[1] == expected[1], f'The variables in the Markov blanket are not correct.\\n Expected: {expected[1]}\\nGiven: {actual[1]}'\n",
    "\n",
    "assert expected[0].shape == actual[0].shape, f'\\nResampling distribution has the wrong shape!\\nExpected: {expected[0].shape}\\nGiven:\\t  {actual[0].shape}'\n",
    "assert expected[0].dtype == actual[0].dtype, f'\\nWrong numpy array data type!\\nExpected: {expected[0].dtype}\\nGiven:\\t  {actual[0].dtype}'\n",
    "assert np.all(np.isclose(expected[0], actual[0])), f'Computation of resampling distribution did not yield the correct result.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37120bda254f42526b380a9f8b157045",
     "grade": false,
     "grade_id": "cell-19c55071121f95ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Gibbs Sampling\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Implement the <i>sample_gibbs</i> function. (3 points)\n",
    "</div>\n",
    "\n",
    "`sample_gibbs` takes five parameters:\n",
    "- `bayes_net` is a `BayesNet` object to draw samples from (it uses your `resampling_distribution()` from above).\n",
    "- `sample_size` is the number of samples to use for the estimation.\n",
    "- `evidence` is a dictionary of variable_ids (keys) and values (values) assigned to the variable. (optional, default = {})\n",
    "- `burn_in_samples` gives the number of burn-in steps to take (>= 0). (optional, default = 0)\n",
    "- `sample_distance` gives the number of steps to take to get the next sample (> 0). (optional, default = 1)\n",
    "\n",
    "`sample_gibbs` function must return one object:\n",
    "- samples from $P_{\\mathcal{B}}( \\mathbf{Y} \\mid \\mathbf{E}=\\mathbf{e})$ of type `np.ndarray`, with shape `(sample_size, len(bayes_net))`\n",
    "\n",
    "\n",
    "Initialize the Markov chain with a random event drawn from $\\mathcal{B}_{\\mathbf{E}=\\mathbf{e}}$. The first element in the sample is the random event obtained after performing a total of `burn_in_samples` steps. Thereafter, perform `sample_distance` steps to obtain each one of the next `sample_size` samples. Hence, `burn_in_samples + (sample_size - 1) * sample_distance` steps will be performed in total.\n",
    "\n",
    "To make your implementation comparable to ours, sample the new values for the non-evidence variables in the topological order provided by the BayesNet class, i.e. `for variable in bayes_net: ...`.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "- `sample_lw(bayes_net, 1, evidence=evidence)[0]` draws an initial sample from $\\mathcal{B}_{\\mathbf{E}=\\mathbf{e}}$\n",
    "  - we implemented and imported `sample_lw` for you; no need to copy-paste it from the previous problem set!\n",
    "- the pre-computation of the re-sampling distributions is handled by the BayesNet (we pass your `resampling_distribution` function to the BayesNet object at instantiation time)\n",
    "- to obtain the distribution $P(X \\mid \\mathit{mb}(X))$, simply call `variable(sample, resampling=True)`; this uses the precomputed re-sampling distribution instead of `variable.pdt`, and is only available because we passed `resampling_distribution` to the BayesNet constructor\n",
    "- it may help to define a function that performs $n$ Gibbs steps on a sample, and reuse it &mdash; you can even define a local function in the middle of `sample_gibbs()`! mind that Python arguments are passed by reference, use `.copy()` on an `ndarray` if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7150b207c07a213290a3c7ed5c642d7f",
     "grade": false,
     "grade_id": "cell-5bffad00b80764bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sample_gibbs(bayes_net: BayesNet, sample_size: int, evidence: dict={}, burn_in_samples: int=0, \n",
    "                 sample_distance: int=1):\n",
    "    '''\n",
    "    Returns sample_size samples from the target distribution P( Y | E=e ).\n",
    "    :param bayes_net: A Bayesian network of type BayesNet.\n",
    "    :param sample_size: The number of samples to use for the estimation.\n",
    "    :param evidence: A dictionary of evidence variables (keys, int) and their correponding values (values, int).\n",
    "    :param burn_in_samples: The number of burn-in samples to throw away (>= 0).\n",
    "    :param sample_distance: Use only every n-th sample. (> 0)\n",
    "    :returns: A NumPy array of type np.int64 with shape (sample_size, len(bayes_net)).\n",
    "    '''\n",
    "    \n",
    "    assert burn_in_samples >= 0\n",
    "    assert sample_distance > 0\n",
    "    \n",
    "    samples = np.empty((sample_size, len(bayes_net)), np.int64)\n",
    "    \n",
    "    # the initial sample to start the Markov chain with\n",
    "    sample = sample_lw(bayes_net, 1, evidence=evidence)[0].squeeze()\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdcb998fbd309566ecdf75f471044071",
     "grade": true,
     "grade_id": "cell-4c54221d4bd46592",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get_default_bayes_net returns the same Bayes net as defined above; just in case the variable was modified...\n",
    "# this time we also pass the function to pre-compute the resampling distributions\n",
    "bayes_net = get_default_bayes_net(resampling_distribution=resampling_distribution)\n",
    "\n",
    "np.random.seed(0)\n",
    "expected = np.array([[0, 0, 0, 1, 0], [0, 0, 0, 0, 0], [0, 0, 1, 0, 0],\n",
    "                     [0, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 1, 1]], dtype=np.int64)\n",
    "actual = sample_gibbs(bayes_net, 6, {0:0}, 7, 3)\n",
    "\n",
    "# sanity checks\n",
    "assert type(actual) == type(expected), f'\\nWrong output type!\\nExpected: {type(expected)}\\nGiven:\\t  {type(actual)}'\n",
    "assert actual.shape == expected.shape, f'\\nWrong output shape!\\nExpected: {expected.shape}\\nGiven:\\t  {actual.shape}'\n",
    "assert actual.dtype == expected.dtype, f'\\nWrong numpy array data type!\\nExpected: {expected.dtype}\\nGiven:\\t  {actual.dtype}'\n",
    "assert np.all(np.isclose(actual, expected)), f'samples and reference samples do not match.\\nExpected:\\n{expected}\\n\\nGiven:\\n{actual}\\n\\nIf your last two samples are the same, this may hint at a bug.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5eb0edcbdeee0d930f07568577f6571",
     "grade": false,
     "grade_id": "cell-f980ef62e03bc242",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Implement the <i>gibbs_sampling</i> function to estimate the probability distribution over the query variable $X$ given the evidence $\\mathbf{E}=\\mathbf{e}$, $P(X \\mid \\mathbf{E}=\\mathbf{e})$. (2 points)\n",
    "</div>\n",
    "\n",
    "`gibbs_sampling` takes six parameters:\n",
    "- `bayes_net` is a `BayesNet` object to draw samples from.\n",
    "- `query_variable_id` is the id of the query variable (int).\n",
    "- `evidence` is a dictionary of variable_ids (keys) and values (values) assigned to the variable. (optional, default = {})\n",
    "- `sample_size` gives the number of samples to use for the estimation (optional, default = 100).\n",
    "- `burn_in_samples` gives the number of burn-in samples to throw away (>= 0). (optional, default = 0)\n",
    "- `sample_distance` gives the number of steps to take to get the next sample (> 0). (optional, default = 1)\n",
    "\n",
    "`gibbs_sampling` function must return one object:\n",
    "-  The probability distribution over variable $X$ of type `np.ndarray` with shape `(bayes_net[query_variable_id].num_values,)`.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "- use `np.bincount` to count the number of occurrences of each value; don't forget to set minlength\n",
    "- the number of values a variable can take can be obtained via `variable.num_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b68aa1c4679be9357283ccf88582d0d1",
     "grade": false,
     "grade_id": "cell-01863042be3b4d68",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gibbs_sampling(bayes_net: BayesNet, query_variable_id: int, evidence: dict={}, \n",
    "                   sample_size: int=100, burn_in_samples: int=0, sample_distance: int=1):\n",
    "    '''\n",
    "    Estimates the distribution of the query variale given the value of the evidence variables.\n",
    "    :param bayes_net: A Bayesian network of type BayesNet.\n",
    "    :param query_variable_id: The id of the query variable (int).\n",
    "    :param evidence: A dictionary of evidence variables (keys, int) and their correponding values (values, int).\n",
    "    :param sample_size: The number of samples to use for the estimation.\n",
    "    :burn_in_samples: The number of burn-in samples to throw away (>= 0).\n",
    "    :param sample_distance: Use only every n-th sample. (> 0)\n",
    "    :returns: A NumPy array of type np.float64 representing the conditional distribution of the query variable given evidence. \n",
    "    '''\n",
    "    \n",
    "    # draw samples...\n",
    "    smpls = sample_gibbs(\n",
    "        bayes_net, \n",
    "        sample_size, \n",
    "        evidence=evidence, \n",
    "        burn_in_samples=burn_in_samples, \n",
    "        sample_distance=sample_distance\n",
    "    )\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b5954cf8865ccf0400b2185dcfd4f7e",
     "grade": true,
     "grade_id": "cell-4b6cfd6dfcb9aeaa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get_default_bayes_net returns the same Bayes net as defined above; just in case the variable was modified...\n",
    "# again, we also pass the function to pre-compute the resampling distributions\n",
    "bayes_net = get_default_bayes_net(resampling_distribution=resampling_distribution)\n",
    "\n",
    "np.random.seed(0)\n",
    "expected = np.array([0.25, 0.75], dtype=np.float64)\n",
    "actual = gibbs_sampling(bayes_net, 0, {2:1}, 100, 5, 3)\n",
    "\n",
    "# sanity checks\n",
    "assert type(actual) == type(expected), f'\\nWrong output type!\\nExpected: {type(expected)}\\nGiven:\\t  {type(actual)}'\n",
    "assert actual.shape == expected.shape, f'\\nWrong output shape!\\nExpected: {expected.shape}\\nGiven:\\t  {actual.shape}'\n",
    "assert actual.dtype == expected.dtype , f'\\nWrong numpy array data type!\\nExpected: {expected.dtype}\\nGiven:\\t  {actual.dtype}'\n",
    "assert  np.all(np.isclose(actual, expected)), f'Wrong output value.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82552f47eda7fdd42900d3405d50e5e5",
     "grade": false,
     "grade_id": "cell-6b71a5c25f4de499",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "\n",
    "Consider the following Bayesian Network:\n",
    "\n",
    "<img width='30%' src='img/bn.svg'>\n",
    "\n",
    "The conditional probability tables are given as:\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>-</td><td>0.2</td><td>0.8</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(C)</th><th>$c_0$<br></th><th>$c_1$</th></tr><tr><td>-</td><td>0.9</td><td>0.1</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(B | A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>$b_0$</td><td>0.9</td><td>0.2</td></tr><tr><td>$b_1$</td><td>0.1</td><td>0.8</td></tr></table>\n",
    "\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th rowspan=\"2\">P(D | B, C)</th><th colspan=\"2\">$b_0$<br></th><th colspan=\"2\">$b_1$</th></tr><tr><td>$c_0$</td><td>$c_1$</td><td>$c_0$</td><td>$c_1$</td></tr><tr><td>$d_0$<br></td><td>0.1</td><td>0.2</td><td>0.99</td><td>0.8</td></tr><tr><td>$d_1$</td><td>0.9</td><td>0.8</td><td>0.01</td><td>0.2</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(E | C)</th><th>$c_0$</th><th>$c_1$</th></tr><tr><td>$e_0$</td><td>0.7</td><td>0.4</td></tr><tr><td>$e_1$</td><td>0.3</td><td>0.6</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "455c7409e034f50d0d865c6f96c48c6a",
     "grade": false,
     "grade_id": "cell-1ff7d8ff45f4c36e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bayes_net = get_default_bayes_net(resampling_distribution=resampling_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a9fb2d1359afc365da53fd8adefd326",
     "grade": false,
     "grade_id": "cell-5dc000e76026780b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Comparison\n",
    "\n",
    "Run the following code cell to plot the average [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the exact distribution $P(A \\mid D, E)$ and the approximations computed with Gibbs sampling. Different lines represent different value assignments to the evidence variables $D$ and $E$.\n",
    "\n",
    "**Hint**: The computation of the approximations might take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc23d099f47c3c64ed480c1eac7a0a33",
     "grade": false,
     "grade_id": "cell-752ca4bf80183a1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from utils import approx_error\n",
    "\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A = np.array([0.2, 0.8])\n",
    "B_A = np.array([[0.9, 0.2], [0.1, 0.8]])\n",
    "C = np.array([0.9, 0.1])\n",
    "D_BC = np.array([[[0.1, 0.2], [0.99, 0.8]], [[0.9, 0.8], [0.01, 0.2]]])\n",
    "E_C = np.array([[0.7, 0.4], [0.3, 0.6]])\n",
    "\n",
    "ABCDE = A[:, None, None, None, None] * B_A.T[:, :, None, None, None] * C [None, None, :, None, None] \\\n",
    "        * D_BC.transpose(1, 2, 0)[None, :, :, :, None] * E_C.T[None, None, :, None, :]\n",
    "ADE = ABCDE.sum(axis=(1, 2))\n",
    "A_DE = ADE / ADE.sum(axis=0)[None, :, :]\n",
    "\n",
    "np.random.seed(0)\n",
    "errs = {}\n",
    "sample_counts = np.array([10, 20, 40, 80, 160 , 320, 640, 1280])\n",
    "\n",
    "# compute approximation error\n",
    "for d, e in zip([0, 0, 1, 1], [0, 1, 0, 1]):\n",
    "    errs[(d, e)] = approx_error(\n",
    "        bayes_net,\n",
    "        gibbs_sampling,  \n",
    "        A_DE[:, d, e],\n",
    "        _A_,\n",
    "        {_D_:d, _E_:e}, \n",
    "        sample_counts,\n",
    "        n_runs=100,\n",
    "        burn_in_samples=0,\n",
    "        sample_distance=1\n",
    "    )\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Kullback-Leiber Divergence')\n",
    "for d, e in zip([0, 0, 1, 1], [0, 1, 0, 1]):\n",
    "    plt.plot(sample_counts, errs[(d, e)], label=f'e:{e}, d:{d}', lw=2)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(sample_counts.min(), sample_counts.max())\n",
    "plt.xlabel('Number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7146e287464bdafad955b71d2c2f2ed",
     "grade": false,
     "grade_id": "cell-e8cbe8dab5f9ad38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Answer the following question. Keep your answer <b>concise</b>! (1 point)\n",
    "</div>\n",
    "\n",
    "Given the Bayesian Network from the example above, we want to approximate the probabilistic query $P(A \\mid D=1, E=1)$. Consider the two cases:\n",
    "\n",
    "* (1): We draw 100 samples from our implemented ```sample_gibbs``` function. \n",
    "* (2): We draw a total of 100 samples from our implemented ```sample_gibbs``` function. However, we start drawing samples only after we have performed 100 Gibbs Sampling steps, and we only take every 10th sample afterwards.\n",
    "\n",
    "We approximate the result of the probabilistic query with the 100 samples drawn for each of the two scenarios (1) and (2). For which scenario do you expect the smaller approximation error? Explain why!\n",
    "\n",
    "**Hint**: Use the code cell below to perform whatever analysis supports your answer. You can, for example, use the ```approx_error``` function (used to create the plot above) and experiment with the parameters ```burn_in_samples``` and ```sample_distance```. \n",
    "\n",
    "**Note**: Only your textual answer will be graded. The code cell only allows you to check if your intuition is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b788de446d92b656e3ad6c10666e455",
     "grade": false,
     "grade_id": "cell-1bfb83a334d5bd46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can freely use this code cell to support your answer to the question.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77689a01a9a8ccce82271432bd8d1d42",
     "grade": true,
     "grade_id": "cell-dfc2020a1b55731c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be387da32f8a12894532edd020407983",
     "grade": false,
     "grade_id": "cell-d7fc0978a0ad0d7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Answer the following question. Keep your answer <b>concise</b>! (2 point)\n",
    "</div>\n",
    "\n",
    "Consider the Bayesian Network below consisting of three binary variables, $C_1$, $C_2$, and $Z$. $C_1$ and $C_2$ are two uniformly distributed, independent coins. $Z$ is the Exclusive OR applied to the outcome of $C_1$ and $C_2$. Can we successfully estimate the probabilistic query $P(C_1, C_2 \\mid Z=1)$ using Gibbs Sampling? <b>Justify your answer!</b>\n",
    "  \n",
    "**Hint**: Use the code cell below to perform whatever analysis supports your answer. You may want to create the Bayesian Network defined below and pass it to your implemented ```sample_gibbs``` function. Look at the samples generated. Do you see a pattern?\n",
    "\n",
    "**Note**: Only your textual answer will be graded. However, the code cell allows you to check if your explanation is correct.\n",
    "\n",
    "<img width='30%' src='img/xor.png'>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(C1)</th><th>$\\neg$$c_1$<br></th><th>$c_1$</th></tr><tr><td>-</td><td>0.5</td><td>0.5</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(C2)</th><th>$\\neg$$c_2$<br></th><th>$c_2$</th></tr><tr><td>-</td><td>0.5</td><td>0.5</td></tr></table>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th rowspan=\"2\">P($Z$ | $C_1$, $C_2$)</th><th colspan=\"2\">$\\neg$$c_1$<br></th><th colspan=\"2\">$c_1$</th></tr><tr><td>$\\neg$ c_2</td><td>c_2</td><td>$\\neg$ c_2</td><td>c_2</td></tr><tr><td>$\\neg$ z<br></td><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>z</td><td>0</td><td>1</td><td>1</td><td>0</td></tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d73e3b390730e43ef426efc168d62ff",
     "grade": false,
     "grade_id": "cell-01e121868322075d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You can freely use this code cell to support your answer to the question.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37f019f1c25f9aa0e5e43136736ec36d",
     "grade": true,
     "grade_id": "cell-3e12685113f7d2cb",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
