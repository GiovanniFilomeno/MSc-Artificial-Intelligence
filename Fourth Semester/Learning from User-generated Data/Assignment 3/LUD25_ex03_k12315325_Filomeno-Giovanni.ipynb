{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eca0f09",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2025*\n",
    "# Exercise 3: Model-based approaches\n",
    "In this exercise we'll have a look at two different takes on Matrix Factorization and prepare to learn about ways to evaluate recommender systems.\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\\\n",
    "LUD25_ex03_k<font color='red'>\\<Matr. Number\\></font>_<font color='red'>\\<Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD25_ex03_k000007_Bond-James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise, as before, you are required to write a number of functions. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency.\n",
    "\n",
    "Please **only use libraries already imported in the notebook**. *Feel free to experiment with the notebook, but clean it up before submitting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a10fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def inter_matr_implicit(users: pd.DataFrame,\n",
    "                        items: pd.DataFrame,\n",
    "                        interactions: pd.DataFrame,\n",
    "                        dataset_name: str,\n",
    "                        threshold=1) -> np.ndarray:\n",
    "    '''\n",
    "    dataset_name - string out of [\"lfm-ismir\", \"ml-1m\"] ,name of the dataset, used for loading user, item and interaction files;\n",
    "    threshold - int > 0, criteria of a valid interaction\n",
    "\n",
    "    returns - 2D np.array, rows - users, columns - items;\n",
    "    '''\n",
    "\n",
    "    res = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION\n",
    "\n",
    "    # getting number of users and items from the respective files to be on the safe side\n",
    "    n_users = len(users.index)\n",
    "    n_items = len(items.index)\n",
    "\n",
    "    # preparing the output matrix\n",
    "    res = np.zeros([n_users, n_items], dtype=np.int8)\n",
    "\n",
    "    # for every interaction assign 1 to the respective element of the matrix\n",
    "    if dataset_name == 'lfm-ismir':\n",
    "        inter_column_name = 'listening_events'\n",
    "    elif dataset_name == 'ml-1m':\n",
    "        inter_column_name = 'rating'\n",
    "    elif dataset_name == 'lfm-tiny':\n",
    "        inter_column_name = 'listening_events'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid dataset name: {dataset_name} \")\n",
    "\n",
    "    row = interactions[\"user_id\"].to_numpy()\n",
    "    col = interactions[\"item_id\"].to_numpy()\n",
    "\n",
    "    data = interactions[inter_column_name].to_numpy()\n",
    "    data[data < threshold] = 0\n",
    "    data[data >= threshold] = 1\n",
    "\n",
    "    res[row, col] = data\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ffd1b9",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "In the previous exercise we implemented ItemKNN which is a Memory-based approach. It means that in order for the model to function we have to keep all known to us interactions (the full interaction matrix) in the memory, this can be cumbersome.\n",
    "    \n",
    "The idea of Model-based approaches is to learn some kind of compact representation of the matrix. Most common scenario is the following: instead of representing every user through all the items and every item through all the users (full interaction matrix) let's represent both in a latent vector space of some smaller dimensionality **f**.\n",
    "\n",
    "It means that instead of the one full interaction matrix **inter**: (**users** x **items**) we'll need to keep in memory two much smaller matrices: one with user-representations **U**: (**users** x **f**), one with item representations **V**: (**items** x **f**). And we'll learn those two in such a way that we can recreate the information contained in the full interaction matrix, for example through dot product:\n",
    "    \n",
    "inter[**user**, **item**] = U[**user**, :] @ V[**item**, :].T\n",
    "    \n",
    "Such approach is generally called Matrix Factorization, because we split one huge unbearable matrix into multiple smaller bearable ones. It has the following benefits:\n",
    "* The two new matrices combined (should) take less space than the full interaction matrix and thus easier fit into memory;\n",
    "* Selecting a reasonable **f** means that we operate with shorter vectors during all kinds of calculations, this decreases computational load during recommendation making online inference easier;\n",
    "* Matrix factorization compresses sparce information contained in the interaction matrix into an elegant representation and can potentially encode **hidden dependencies**;\n",
    "* Having both items and users represented in the the same **f**-dimensional space opens new possibilities for recommendation;\n",
    "    \n",
    "Now let's have a look at how we can actually perform this trick.\n",
    "    \n",
    "### Singular Value Decomposition (SVD)\n",
    "As it often happens, linear algebra has answers. And Singular Vector Decomposition is one.\n",
    "\n",
    "A $n * m$ matrix $I$ can be decomposed into a product of 3 matrices:<br>\n",
    "$I = U\\Sigma V^T$\n",
    "\n",
    "$U$ -- orthogonal ($n * n$) matrix composed of left singular vectors (it corresponds to users);<br>\n",
    "$\\Sigma$ -- ($n * m$) diagonal matrix, containing singular values;<br>\n",
    "$V$ -- orthogonal ($m * m$) matrix composed of right singular vectors (it corresponds to items);<br>\n",
    "\n",
    "#### <font color='#666666'>Thin Variant</font> of  Singular Vector Decomposition\n",
    "As before:<br>\n",
    "$I = U\\Sigma V^T$\n",
    "\n",
    "We can exploit the fact that $I$ (usually) is not square and cannot have *full rank*.<br>\n",
    "$k = min(n, m)$\n",
    "\n",
    "As a result $U$, $\\Sigma$ and $V$ have different dimensions:<br>\n",
    "$U$ -- ($n *$ <font color='red'>$k$</font>) of left singular vectors (it corresponds to users);<br>\n",
    "$\\Sigma$ -- (<font color='red'>$k$</font> $*$ <font color='red'>$k$</font>) square diagonal matrix, containing singular values;<br>\n",
    "$V$ -- ($m *$ <font color='red'>$k$</font>) of right singular vectors (it corresponds to items);<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745c1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users' representations:\n",
      " [[ 5.42463675e-01  9.81751217e-02  7.07106781e-01  4.42825933e-01]\n",
      " [ 5.97192605e-01 -5.10969410e-01  1.27675648e-15 -6.18280887e-01]\n",
      " [ 2.34152336e-01  8.48312179e-01 -1.90321752e-15 -4.74909602e-01]\n",
      " [ 5.42463675e-01  9.81751217e-02 -7.07106781e-01  4.42825933e-01]] \n",
      "\n",
      "items' representations:\n",
      " [[ 4.42491536e-01 -2.76337063e-01 -5.00000000e-01 -4.77324909e-01]\n",
      " [ 3.01534785e-01  6.33607412e-01  5.00000000e-01 -8.72835678e-02]\n",
      " [ 4.42491536e-01 -2.76337063e-01  5.00000000e-01 -4.77324909e-01]\n",
      " [ 6.53112570e-01 -2.10615648e-01  7.98555302e-16  7.27382307e-01]\n",
      " [ 3.01534785e-01  6.33607412e-01 -5.00000000e-01 -8.72835678e-02]] \n",
      "\n",
      "singular values: [2.57554368 1.49380718 1.41421356 0.36757971] \n",
      "\n",
      "reconstructed matrix\n",
      " [[ 8.18825761e-17  1.00000000e+00  1.00000000e+00  1.00000000e+00\n",
      "   5.09615254e-17]\n",
      " [ 1.00000000e+00  6.48779226e-16  1.00000000e+00  1.00000000e+00\n",
      "   6.53512172e-16]\n",
      " [ 1.20009707e-16  1.00000000e+00  5.10143746e-16  2.51476196e-16\n",
      "   1.00000000e+00]\n",
      " [ 1.00000000e+00 -2.17702509e-16  1.00352750e-16  1.00000000e+00\n",
      "   1.00000000e+00]] \n",
      "\n",
      "reconstructed matrix (rounded)\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# consider an interaction matrix with 4 users and 5 items\n",
    "inter_matr = np.array(\n",
    "    [\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 0, 1, 1, 0],\n",
    "        [0, 1, 0, 0, 1],\n",
    "        [1, 0, 0, 1, 1]\n",
    "    ]\n",
    ")\n",
    "# let's now apply Thin (k==4) SVD to it, we'll get the following: \n",
    "\n",
    "# U - (4, 4) matrix, corresponding to users\n",
    "# s - (4) singular values - each element shows how informative the corresponding dimension is\n",
    "# Vh - (4, 5) already transposed matrix corresponding to items\n",
    "\n",
    "# we set 'full_matrices' to 'False' for Thin SVD\n",
    "U, s, Vh = np.linalg.svd(inter_matr, full_matrices=False)\n",
    "\n",
    "# let's quickly construct the matrix back to make sure everything works\n",
    "res = (U @ np.diag(s)) @ Vh\n",
    "\n",
    "print('users\\' representations:\\n', U, '\\n')\n",
    "print('items\\' representations:\\n', Vh.T, '\\n')  # Transposing to have first dimension correspond to items\n",
    "print('singular values:', s, '\\n')\n",
    "print('reconstructed matrix\\n', res, '\\n')\n",
    "print('reconstructed matrix (rounded)\\n', res.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3861841e",
   "metadata": {},
   "source": [
    "#### Cool things about SVD\n",
    "SVD projects all the variance contained in the data onto orthogonal basis of $k$ vectors.<br>\n",
    "Singular values ($\\Sigma$ or $s$) allow us to judge how much variance is \"situated\" along each vector. It also acts as weighting for the $k$ dimensions;\n",
    "\n",
    "| $\\Sigma$ |  |  |  |\n",
    "|--|--|--|--|\n",
    "| **2.58** | 0.0 | 0.0 | 0.0 |\n",
    "| 0.0 | **1.49** | 0.0  | 0.0 |\n",
    "| 0.0 | 0.0 | **1.41** | 0.0 |\n",
    "| 0.0 | 0.0 | 0.0 | **0.37** |\n",
    "\n",
    "Basing on that, we can choose $f < k$ (remember $f$?â¬†) dimensions to represent the whole data. Choosing dimensions corresponding to largest singular values we make sure to keep most of the information contained in the full interaction matrix while decreasing its size and maybe even filtering some noise out. $U$ and $V^T$ become ($n *$ <font color='red'>$f$</font>) and (<font color='red'>$f$</font> $* m$) respectively.<br><br>\n",
    "Let's select only $f = 2$ or $3$ **first** latent features out of $4$ we got, and check how the matrix will change. This is called **truncated SVD**.\n",
    "\n",
    "**Note!** We take first $f$ latent features, because they correspond to higher variance (usually SVD implementations arrange the dimensions in the order of decreasing variance). Higer variance means more *signal* captured with the corresponding dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba63983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed interaction matrix with f = 4, no truncation:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]]\n",
      "reconstructed interaction matrix with f =  3 , truncated:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1. -0.  1.  1. -0.]\n",
      " [-0.  1. -0.  0.  1.]\n",
      " [ 1.  0.  0.  1.  1.]]\n",
      "reconstructed interaction matrix with f =  2 , truncated:\n",
      " [[ 1.  1.  1.  1.  1.]\n",
      " [ 1. -0.  1.  1. -0.]\n",
      " [-0.  1. -0.  0.  1.]\n",
      " [ 1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print('reconstructed interaction matrix with f = 4, no truncation:\\n', res.round())\n",
    "\n",
    "# Taking 3 most informative dimensions\n",
    "f = 3\n",
    "res_trunc_3 = (U[:, :f] @ np.diag(s[:f])) @ Vh[:f, :]\n",
    "print('reconstructed interaction matrix with f = ', f, ', truncated:\\n', res_trunc_3.round())\n",
    "\n",
    "# Taking only 2 most informative dimensions\n",
    "f = 2\n",
    "res_trunc_2 = (U[:, :f] @ np.diag(s[:f])) @ Vh[:f, :]\n",
    "print('reconstructed interaction matrix with f = ', f, ', truncated:\\n', res_trunc_2.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068c3dc",
   "metadata": {},
   "source": [
    "You can notice that selecting 3 most informative features gives a result very similar to the full set of features. This is no wonder, the 4th dimension corresponds to the lowest variance of 0.37, see the table above.\n",
    "\n",
    "Selecting 2 most informative features gives visible difference in the result even within our toy example.\n",
    "\n",
    "#### Final representations\n",
    "Our goal with matrix factorization is to have two matrices: one for users and the other for items. Right now we have an array of weights (singular values) in addition to this. For the sake of convenience let's just merge those weights into the two matrices (see lecture slides):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fead77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction Matrix reconstructed through U, V and s:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]] \n",
      "\n",
      "Interaction Matrix reconstructed through U_final and V_final:\n",
      " [[ 0.  1.  1.  1.  0.]\n",
      " [ 1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  1.]\n",
      " [ 1. -0.  0.  1.  1.]] \n",
      "\n",
      "Original Interaction Matrix:\n",
      " [[0 1 1 1 0]\n",
      " [1 0 1 1 0]\n",
      " [0 1 0 0 1]\n",
      " [1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "U_final = U @ np.diag(s ** 0.5)  # users x features\n",
    "V_final = (np.diag(s ** 0.5) @ Vh).T  # items x features\n",
    "\n",
    "print('Interaction Matrix reconstructed through U, V and s:\\n', ((U @ np.diag(s)) @ Vh).round(), '\\n')\n",
    "print('Interaction Matrix reconstructed through U_final and V_final:\\n', (U_final @ V_final.T).round(), '\\n')\n",
    "print('Original Interaction Matrix:\\n', inter_matr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3df8d",
   "metadata": {},
   "source": [
    "Now in the two final matrices of representations U_final and V_final we essentially have user- and item-embeddings stored. All what is left is to truncate them to our liking (select $f$ first dimensions) and proceed to recommendation.\n",
    "\n",
    "Reasons to truncate:\n",
    "* Save space in memory\n",
    "* Dimensions with lower corresponding variance are likely to contain noise. Truncating the representations we concentrate on the strongest patterns\n",
    "\n",
    "#### Recommendation with Matrix Factorization\n",
    "With the two sets of embeddings U_final and V_final there is a multitude of ways to recommend items to users.\n",
    "In this exercise we take advantage of the fact that we represent both users and items in the same f-dimensional vector space. It means that we can estimate similarity directly between users and items. The obvious choice would be dot product, as it allows to reconstruct the full interaction matrix.\n",
    "\n",
    "So to recommend items for a user with id **u** we would create a list of all items ranked according to the dot product between the user vector U_final[**u**,:] and corresponding item-vectors from V_final (V_final[**i**, :], make sure to take the correct orientation of the matrix). Then as before we should remove items already seen by the user and take Top K (how ever many recommendations we need) of the resulting list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb9d59",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/2</font>: Matrix Factorization with SVD\n",
    "Complete the templates below to create an MF-SVD recommender.\\\n",
    "The first function should return two sets of embeddings (for users and for items) of given length (Truncated SVD!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5a0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_decompose(inter_matr: np.ndarray, f: int = 50) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    inter_matr - np.ndarray, interaction matrix to construct svd from;\n",
    "    f - int, expected size of embeddings;\n",
    "    \n",
    "    returns - 2D np.ndarray, U_final &  2D np.ndarray, V_final (as above) user-/item-embeddings of given length f;\n",
    "    \"\"\"\n",
    "\n",
    "    U_final = None\n",
    "    V_final = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENATION.\n",
    "\n",
    "    U, s, Vh = np.linalg.svd(inter_matr, full_matrices=False) \n",
    "\n",
    "    U_f = U[:, :f]            # size: (num_users, f)\n",
    "    s_f = s[:f]               # size: (f,)\n",
    "    Vh_f = Vh[:f, :]          # size: (f, num_items)\n",
    "\n",
    "    sqrt_s = np.diag(np.sqrt(s_f))   # size: (f, f)\n",
    "\n",
    "    U_final = U_f @ sqrt_s          # size: (num_users, f)\n",
    "    V_final = (sqrt_s @ Vh_f).T     # size: (num_items, f)\n",
    "\n",
    "    return U_final, V_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652a28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LFM-Tiny dataset from exercise 1\n",
    "users = pd.read_csv('lfm-tiny-tunes-sample/lfm-tiny-tunes.user', sep='\\t')\n",
    "items = pd.read_csv('lfm-tiny-tunes-sample/lfm-tiny-tunes.item', sep='\\t')\n",
    "interactions = pd.read_csv('lfm-tiny-tunes-sample/lfm-tiny-tunes.inter', sep='\\t')\n",
    "\n",
    "train_data_inter = inter_matr_implicit(users, items, interactions, \"lfm-tiny\", 1)\n",
    "\n",
    "U, V = svd_decompose(train_data_inter, 60)\n",
    "\n",
    "assert U is not None and V is not None, \"The variables should not be None.\"\n",
    "assert U.shape == (1215, 60), \"U has incorrect shape\"\n",
    "assert V.shape == (394, 60), \"V has incorrect shape\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a43e4",
   "metadata": {},
   "source": [
    "The function below is meant for recommendation. Given a User id, an array with item ids consumed by the respective user, U_final, V_final and expected number of recommendations, the function returns an array of recommendations for the user. The items, as before, should be ordered from most to least recommended. Make sure to ignore already seen items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a827d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_recommend(user_id: int, seen_item_ids: np.ndarray, U: np.ndarray, V: np.ndarray, topK: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommend with svd to selected users\n",
    "\n",
    "    user_id - int - id of target user.\n",
    "    seen_item_ids - 1D np.ndarray, ids of items already seen by the users (to exclude from recommendation)\n",
    "    U and V - user- and item-embeddings\n",
    "    topK - number of recommendations per user to be returned\n",
    "\n",
    "    returns - np.ndarray - list of ids of recommended items in the order of descending score\n",
    "                           use -1 as a place holder item index, when it is impossible to recommend topK items\n",
    "    \"\"\"\n",
    "    recs = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "    scores = U[user_id] @ V.T\n",
    "    scores[seen_item_ids] = -np.inf # so that then ranking they will go down\n",
    "    rank_items = np.argsort(-scores)\n",
    "    top_k_items = rank_items[:topK] # top K \n",
    "\n",
    "    if len(top_k_items) < topK: # padding in case size does not match\n",
    "        top_k_items = np.concatenate(\n",
    "            [top_k_items, np.full(topK - len(top_k_items), -1)]\n",
    "        )\n",
    "\n",
    "    recs = top_k_items\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed68be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89, 117, 137, 133,   6,  53, 183,  26,  10, 296])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 5\n",
    "seen_list = np.where(train_data_inter[user_id] != 0)[0]\n",
    "\n",
    "recs = svd_recommend(user_id, seen_list, U, V, 10)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c5e4d",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/2</font>: Iterative Matrix Factorization with PyTorch\n",
    "\n",
    "In the first task we utilized a deterministic method (SVD) to obtain user- and item-embeddings. It means that an equation needs to be solved every time we do so, and the whole process (for the whole matrix) needs to be repeated from time to time to take into account a new item, new user or new interactions in the system. Notice also that with SVD we are doing some extra work by first getting the embeddings of length k and then truncating them to our desired length.\n",
    "\n",
    "Iterative approach to MF allows us to train embeddings of the desired length straight away, gives more flexibility in setting the training objective and updating the parameters/adding new users (e.g. through 'fine tuning').\n",
    "\n",
    "Your task is to implement matrix factorization using PyTorch, please follow the specifications closely and referer to the provided introduction to PyTorch (separate notebook). Use Moodle forum if you have any questions.\n",
    "\n",
    "First, you need to construct a module consisting of two layers (those will be our **U_final** and **V_final** that we are after):\n",
    "\n",
    "1) An Embedding Layer from User space to Latent space  (user id -> f-dim vector)<br>\n",
    "2) An Embedding Layer from Item space to Latent space (item id -> f-dim vector)<br>\n",
    "\n",
    "Use the <b>nn.Embedding</b> Module. Implement the forward function: as with SVD we'll set the training objective to reconstruct the interaction matrix. So multiplying U and V (with transposition applied correctly) we should get an approximation of the interaction matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8be18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users: int, n_items: int, n_factors: int):\n",
    "        \"\"\"\n",
    "        n_users - int, number of users;\n",
    "        n_items - int, number of items;\n",
    "        n_factors - int, dimensionality of the latent space;\n",
    "        \"\"\"\n",
    "\n",
    "        super(MF, self).__init__()\n",
    "\n",
    "        self.embedding_user = None\n",
    "        self.embedding_item = None\n",
    "\n",
    "        # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "        self.embedding_user = nn.Embedding(n_users, n_factors)\n",
    "        self.embedding_item = nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user: torch.Tensor, item: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        We allow for some flexibility giving lists of ids as inputs:\n",
    "        if the training data is small we can deal with it in a single forward pass,\n",
    "        otherwise we could fall back to mini-batches, limiting users and items we pass\n",
    "        every time.\n",
    "        \n",
    "        user - torch.Tensor, user_ids;\n",
    "        item - torch.Tensor, item_ids;\n",
    "        \n",
    "        returns - torch.Tensor, Reconstructed Interaction matrix of shape (n_users, n_items);\n",
    "        \"\"\"\n",
    "        u = None\n",
    "        v = None\n",
    "        # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "        u = self.embedding_user(user)\n",
    "        v = self.embedding_item(item)\n",
    "\n",
    "        return (u @ v.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b73ca",
   "metadata": {},
   "source": [
    "We have a model with the two embedding sets, and it is able to reconstruct the interaction matrix through them.\n",
    "\n",
    "Next we need a way to evaluate the reconstruction, this is what loss function helps us with.\n",
    "For our case we will use the Binary Cross Entropy Loss, please implement the compute_loss function and use nn.BCELoss to calculate the loss.\n",
    "\n",
    "<b>Tip:</b> Make sure to first project the logits to the [0, 1] interval using sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d1fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    logits - torch.Tensor, output of model;\n",
    "    labels - torch.Tensor, labels / interaction matrix model should learn to reconstruct;\n",
    "    \n",
    "    returns - torch.Tensor, BCELoss over all logits and labels;\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    probabilities = torch.sigmoid(logits)\n",
    "    bce = nn.BCELoss()\n",
    "    loss = bce(probabilities, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e620a187",
   "metadata": {},
   "source": [
    "We provide an implementation of the train function and return the loss over all epochs.\n",
    "For simplicity, we pass the full interaction matrix (all user and item ids) at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279c1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_data_inter: np.ndarray, epochs: int, optimizer, loss_func) -> list:\n",
    "    \"\"\"\n",
    "    model - nn.Module, torch module to train;\n",
    "    train_data_inter - 2D np.ndarray, interaction matrix of the training data;\n",
    "    epochs - int, number of epochs to perform;\n",
    "    optimizer - optim, optimizer for training;\n",
    "    loss_func - loss function for training;\n",
    "    \n",
    "    returns - list - list of loss values over all epochs;\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    user_ids = torch.Tensor(list(range(train_data_inter.shape[0]))).long()\n",
    "    item_ids = torch.Tensor(list(range(train_data_inter.shape[1]))).long()\n",
    "    y = torch.Tensor(train_data_inter).long()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_hat = model(user_ids, item_ids)\n",
    "\n",
    "        loss = loss_func(y_hat.unsqueeze(0).float(), y.unsqueeze(0).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 100 == 0:\n",
    "            print(\"Loss \", e, \": \", loss.item())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdf223",
   "metadata": {},
   "source": [
    "### Training a model with the following parameters\n",
    "\n",
    "<b>Learning rate:</b> 0.001<br>\n",
    "<b>Optimizer:</b> Adam<br>\n",
    "<b>Factor size:</b> 128<br>\n",
    "\n",
    "Of course, we encourage you to try out multiple different parameters, just for you to get a feeling of this model, but for this exercise we fixed the parameters for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba7785f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do not change the seed.\n",
    "torch.manual_seed(1234)\n",
    "rnd.seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "model_128 = None\n",
    "optimizer = None\n",
    "\n",
    "# TODO: YOUR IMPLEMENATION.\n",
    "# Initialize the model and optimizer as prescribed\n",
    "n_users = train_data_inter.shape[0]\n",
    "n_items = train_data_inter.shape[1]\n",
    "\n",
    "model_128 = MF(n_users=n_users, n_items=n_items, n_factors=128)\n",
    "optimizer = torch.optim.Adam(model_128.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "906795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_128 is not None and optimizer is not None, \"Model and optimizer should be initilized.\"\n",
    "assert type(optimizer) == optim.Adam\n",
    "\n",
    "assert model_128.embedding_user is not None and model_128.embedding_item is not None, \"Embedding Layers need to be not None.\"\n",
    "assert type(model_128.embedding_user) == nn.Embedding, \"Embedding Layer should be of type nn.Embedding.\"\n",
    "assert type(model_128.embedding_item) == nn.Embedding, \"Embedding Layer should be of type nn.Embedding.\"\n",
    "\n",
    "assert model_128.embedding_item.embedding_dim == 128, \"Item Embedding Layer wrong embedding size.\"\n",
    "assert model_128.embedding_user.embedding_dim == 128, \"User Embedding Layer wromg embedding size.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a506b5a",
   "metadata": {},
   "source": [
    "#### Training model\n",
    "\n",
    "Lets train the model for <b>1000</b> epochs and look at the returned loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "201a0fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss  0 :  9.950910568237305\n",
      "Loss  100 :  7.353848934173584\n",
      "Loss  200 :  3.767519235610962\n",
      "Loss  300 :  1.2690845727920532\n",
      "Loss  400 :  0.5857058763504028\n",
      "Loss  500 :  0.39598461985588074\n",
      "Loss  600 :  0.3073318600654602\n",
      "Loss  700 :  0.2509416937828064\n",
      "Loss  800 :  0.20859557390213013\n",
      "Loss  900 :  0.1730194389820099\n"
     ]
    }
   ],
   "source": [
    "loss_model_128 = train(model=model_128,\n",
    "                       train_data_inter=train_data_inter,\n",
    "                       epochs=1000,\n",
    "                       optimizer=optimizer,\n",
    "                       loss_func=compute_loss)\n",
    "\n",
    "assert len(loss_model_128) == 1000, \"Loss should have 1000 elements, one for each epoch.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "322c4710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQb1JREFUeJzt3Xd4VGXC/vF7WiaF9JBGAgTpvYooKooiRZS1KyL+fFdlBYV1d+27+tpwm7IuiovvrmURcS242FCwoAhICYHQBUJPCCWkZ5LMnN8fISORlsAkZ2by/VzXXMmcOTO58+iae895znkshmEYAgAACFBWswMAAACcDcoMAAAIaJQZAAAQ0CgzAAAgoFFmAABAQKPMAACAgEaZAQAAAc1udoDG5vF4tG/fPkVGRspisZgdBwAA1INhGCouLlZqaqqs1lMfewn6MrNv3z6lp6ebHQMAAJyB3bt3Ky0t7ZT7BH2ZiYyMlFQzGFFRUSanAQAA9VFUVKT09HTv3/FTCfoyU3tqKSoqijIDAECAqc8UESYAAwCAgEaZAQAAAY0yAwAAAlrQz5kBAKCpud1uVVVVmR3DrzkcDtlsNp98FmUGAAAfMQxDeXl5OnLkiNlRAkJMTIySk5PP+j5wlBkAAHyktsgkJiYqPDycm7WehGEYKisrU35+viQpJSXlrD6PMgMAgA+43W5vkYmPjzc7jt8LCwuTJOXn5ysxMfGsTjkxARgAAB+onSMTHh5ucpLAUTtWZzu/iDIDAIAPcWqp/nw1VqaWmW+//VajR49WamqqLBaLPvzwwzqvG4ahJ554QqmpqQoLC9OQIUO0fv16c8ICAAC/ZGqZKS0tVa9evTR9+vQTvv6nP/1Jzz//vKZPn64VK1YoOTlZl19+uYqLi5s4KQAA8FemTgAeMWKERowYccLXDMPQtGnT9Oijj+qaa66RJL3xxhtKSkrS7Nmzdffdd5/wfS6XSy6Xy/u8qKjI98EBAIDf8Ns5Mzk5OcrLy9OwYcO825xOpy6++GItWbLkpO+bOnWqoqOjvY/09PRGy7hq52EVlnNTJABAYDvVtI+qqio9+OCD6tGjhyIiIpSamqrbbrtN+/btq/MZeXl5GjdunJKTkxUREaG+ffvqvffea5L8fltm8vLyJElJSUl1ticlJXlfO5GHH35YhYWF3sfu3bsbJd8zn2zQtTOW6pVF2xrl8wEAaCqnmvZRVlamzMxM/f73v1dmZqY++OADbdmyRVdddVWd/caNG6fNmzdr3rx5ys7O1jXXXKMbb7xRq1evbvT8fn+fmZ/PdDYM45Szn51Op5xOZ2PH0sCMeL36XY7+tThH4we1VXJ0aKP/TABAYDEMQ+VVblN+dpjDVu+rhU417SM6OloLFiyos+3vf/+7zj33XO3atUutW7eWJC1dulQzZszQueeeK0l67LHH9MILLygzM1N9+vQ5i9/k9Py2zCQnJ0uqOUJz7J0B8/PzjztaY4ahXRI1oG2sVuwo0LSFW/TctT3NjgQA8DPlVW51/cPnpvzsDU9eofCQxvkzX1hYKIvFopiYGO+2wYMH65133tGoUaMUExOj//znP3K5XBoyZEijZDiW355mysjIUHJycp02WFlZqUWLFun88883MVkNi8Wih0Z0liT9Z+Vubc3nCisAQPCrqKjQQw89pFtuuUVRUVHe7e+8846qq6sVHx8vp9Opu+++W3PnztU555zT6JlMPTJTUlKirVu3ep/n5OQoKytLcXFxat26taZMmaJnn31WHTp0UIcOHfTss88qPDxct9xyi4mpf9KvTZyGdU3SFxv260/zN2vmbf3NjgQA8CNhDps2PHmFaT/b16qqqnTTTTfJ4/Ho5ZdfrvPaY489poKCAi1cuFAJCQn68MMPdf311+u7775Tjx49fJ7lWKaWmZUrV+qSSy7xPr///vslSePHj9frr7+uBx54QOXl5brnnntUUFCggQMH6osvvlBkZKRZkY/zwPBOWrhxv77YsF/ZewrVIy3a7EgAAD9hsVga7VRPU6uqqtINN9ygnJwcffXVV3WOymzbtk3Tp0/XunXr1K1bN0lSr1699N133+mll17SK6+80qjZTD3NNGTIEBmGcdzj9ddfl1TzL8ETTzyh3NxcVVRUaNGiRerevbuZkY/TPjFSV/duJUl6YeEWk9MAAOB7tUXmxx9/1MKFC49bSLOsrEySZLXWrRU2m00ej6fR8/ntnJlAct/QDrJZLfpqU75W7SwwOw4AAA1SUlKirKwsZWVlSfpp2seuXbtUXV2t6667TitXrtRbb70lt9utvLw85eXlqbKyUpLUuXNntW/fXnfffbeWL1+ubdu26a9//asWLFigMWPGNHp+yowPZCRE6Lq+aZKkP87fJMMwTE4EAED9rVy5Un369PFeQn3//ferT58++sMf/qA9e/Zo3rx52rNnj3r37q2UlBTvo/Ymtg6HQ59++qlatmyp0aNHq2fPnnrzzTf1xhtvaOTIkY2ePzhO5PmByZd10NysvVqec1jfbDmgSzolmh0JAIB6qZ32cTL1+T/pHTp00Pvvv+/LWPXGkRkfSY0J0+3nt5Uk/Xn+Znk8HJ0BAKApUGZ86FcXn6MWTrs25Bbp03W5ZscBAKBZoMz4UGxEiO68sJ0k6fkvtqja3fgzuAEAaO4oMz72PxdmKC4iRNsPluqDzL1mxwEANDEuAqk/X40VZcbHWjjtumdIza2bpy3cIle1OQuMAQCalsPhkPTTPVdwerVjVTt2Z4qrmRrBree10f99l6N9hRV6a9ku3TE4w+xIAIBGZrPZFBMTo/z8fElSeHh4vVetbm4Mw1BZWZny8/MVExMjm+3sll6gzDSCUIdN9w3toEfmZuulr7fqxgHpinAy1AAQ7JKTkyXJW2hwajExMd4xOxv8hW0k1/dP08xvt2nHoTL933c5mnxZB7MjAQAamcViUUpKihITE1VVVWV2HL/mcDjO+ohMLcpMI3HYrPrtFZ00afZqzfx2m8ae11oJLZxmxwIANAGbzeazP9Q4PSYAN6KR3VPUo1W0Sivdmv7VVrPjAAAQlCgzjchqtejB4Z0lSbN/2KW9R8pNTgQAQPChzDSyC9rHa1C7eFW6PXpx4Y9mxwEAIOhQZhqZxWLRb6/oJEl6L3OPth8oMTkRAADBhTLTBPq1idVlXRLl9hh6fsEWs+MAABBUKDNN5DfDOslikT5em6vsPYVmxwEAIGhQZppIl5QoXd0rVZL0p883mZwGAIDgQZlpQr8Z1kkOm0Xf/XhQS7YeNDsOAABBgTLThNLjwjV2YBtJ0h/nb2JlVQAAfIAy08QmXdpeESE2rdlTqM/W5ZkdBwCAgEeZaWIJLZz65YXtJEl/+Xyzqt0ekxMBABDYKDMmuPOidoqPCNH2g6X6z8o9ZscBACCgUWZM0MJp16RL20uSpi3covJKt8mJAAAIXJQZk9wysLXSYsOUX+zSv77PMTsOAAABizJjEqfdpt8dXeZgxjfbdLDEZXIiAAACE2XGRKN7pqp7qyiVuKr19y9ZhBIAgDNBmTGR1WrRIyO6SJJmL9+lPQVlJicCACDwUGZMdn77BJ1/Tryq3IZe5OgMAAANRpnxA789Onfm/cy92n6gxOQ0AAAEFsqMH+jbOlZDOyfK7TH0wkKOzgAA0BCUGT9x/7COkqSP1uzTxtwik9MAABA4KDN+oltqtEb1TJEk/fWLLSanAQAgcFBm/MivL+soq0VauHG/Vu8qMDsOAAABgTLjR9onttA1fdMkcXQGAID6osz4mclDO8hhs2jx1oNasu2g2XEAAPB7lBk/kx4XrpsGtJYk/eXzzTIMw+REAAD4N8qMH5p0aXs57VZl7jqirzfnmx0HAAC/RpnxQ0lRoRp/fltJ0l8+3yKPh6MzAACcDGXGT024+By1cNq1IbdIn63LMzsOAAB+izLjp+IiQnTH4AxJ0vMLNsvN0RkAAE6IMuPHfnlhhqLDHNp2oFRzV+81Ow4AAH6JMuPHokIdmnDxOZKkaQu3qLLaY3IiAAD8D2XGz40/v41aRjq1p6Bc/1m52+w4AAD4HcqMnwsPsWvikJqjM9O/2qqKKrfJiQAA8C+UmQBw88DWSo0OVV5RhWb/sMvsOAAA+BXKTABw2m26d2gHSdLL32xVWWW1yYkAAPAflJkAcV2/NLWOC9fBkkq9sWSn2XEAAPAblJkA4bBZNfno0Zl/fLtNxRVVJicCAMA/UGYCyJg+rXROywgdKavSvxbvMDsOAAB+gTITQGxWi6Zc1lGS9H/fbdeRskqTEwEAYD7KTIAZ1SNFnZMjVeyq1j8X55gdBwAA01FmAozVavHOnXn9+x0qLGPuDACgeaPMBKAruiWrU1LN0Zl/fc/RGQBA80aZCUBWq0X3HT0686/vc1RYztEZAEDzRZkJUCO6J6tDYgsVV1Tr9e93mB0HAADT+HWZqa6u1mOPPaaMjAyFhYWpXbt2evLJJ+XxsHq01Wrx3hX4n4u3q4j7zgAAmim/LjN//OMf9corr2j69OnauHGj/vSnP+nPf/6z/v73v5sdzS+M6pGic1pGqKiiWm8u2WF2HAAATOHXZWbp0qW6+uqrNWrUKLVt21bXXXedhg0bppUrV5odzS/YrBbde2nN0Zn/W5yjEhdrNgEAmh+/LjODBw/Wl19+qS1btkiS1qxZo8WLF2vkyJEnfY/L5VJRUVGdRzAb3StV7RJq7gr8BkdnAADNkF+XmQcffFA333yzOnfuLIfDoT59+mjKlCm6+eabT/qeqVOnKjo62vtIT09vwsRNz2a1aNKl7SVJ/1yco/JKt8mJAABoWn5dZt555x3NmjVLs2fPVmZmpt544w395S9/0RtvvHHS9zz88MMqLCz0Pnbv3t2Eic1xVa9UpceF6XBppd5ZscvsOAAANCmLYRiG2SFOJj09XQ899JAmTpzo3fb0009r1qxZ2rRpU70+o6ioSNHR0SosLFRUVFRjRTXdv5ft1O8/XKdWMWH65ndD5LD5dU8FAOCUGvL326//4pWVlclqrRvRZrNxafYJXN8vTQktnNp7pFz/zdpndhwAAJqMX5eZ0aNH65lnntEnn3yiHTt2aO7cuXr++ef1i1/8wuxofifUYdP/DM6QJL2yaJs8Hr894AYAgE/5dZn5+9//ruuuu0733HOPunTpot/+9re6++679dRTT5kdzS/del5rRYbatTW/RAs27jc7DgAATcKv58z4QnOZM1PrT/M36eVvtql3eozm3nO+LBaL2ZEAAGiwoJkzg4a7/YK2CrFblbX7iJbnHDY7DgAAjY4yE2QSI0N1bd80SdI/vt1uchoAABofZSYI3XlhhiwW6atN+dqaX2J2HAAAGhVlJgi1a9lCQzsnSpJeX5JjchoAABoXZSZI3XH0Mu33Vu3RkbJKk9MAANB4KDNBalC7eHVLjVJFlUevswAlACCIUWaClMVi0a+GnCNJeu37HSp1VZucCACAxkGZCWIjuqcoIyFCheVVendl8C+4CQBonigzQcxmtXjnzvzr+x1ys8QBACAIUWaC3LV9Wykm3KFdh8u0YEOe2XEAAPA5ykyQCw+x69aBbSRJ07/eqiBfvQIA0AxRZpqBOwZnKDzEpnV7i/TN5gNmxwEAwKcoM81AXESIbj2v5ujM3778kaMzAICgQplpJu68sJ2cRxegXLrtkNlxAADwGcpMM9Ey0qkb+qdLkt5YusPcMAAA+BBlphkZN6jmVNOCDfuVW1huchoAAHyDMtOMdEyK1Hnt4uQxpNk/7DI7DgAAPkGZaWZuG9RWkvT28t2qrPaYGwYAAB+gzDQzl3dNUlKUUwdLXPpsXa7ZcQAAOGuUmWbGYbPq5nNbS5L+vXSnyWkAADh7lJlm6JZzW8tutWjlzgJt2FdkdhwAAM4KZaYZSowK1RXdkyVJ/162w9wwAACcJcpMM3Xb0TsCf7h6nwrLq0xOAwDAmaPMNFPnZsSpU1Kkyqvcen/VHrPjAABwxigzzZTFYvHeRO/fy3bK42G9JgBAYKLMNGO/6NNKkU67cg6WavHWg2bHAQDgjFBmmrEIp13X9U+TJL3Jek0AgABFmWnmxh2dCPzlpnztPlxmchoAABqOMtPMtWvZQhd1bCnDkGYt4yZ6AIDAQ5mB9+jMu6v2yFXtNjkNAAANQ5mBLunUUklRTh0urdSCDfvNjgMAQINQZiC7zaob+6dLkmb/sMvkNAAANAxlBpKkGwaky2KRlmw7pB0HS82OAwBAvVFmIElKiw3XxR1bSpLeXs7RGQBA4KDMwOuWc1tLYiIwACCwUGbgdWnnRO9E4C/WMxEYABAYKDPwYiIwACAQUWZQR+1E4KXbD2nnISYCAwD8H2UGdaTFhmtw+wRJ0rsr95icBgCA06PM4Dg3Dqg51fTeqj2qdntMTgMAwKlRZnCcy7smKTbcobyiCn374wGz4wAAcEqUGRzHabdpTJ9WkqR3Vuw2OQ0AAKdGmcEJ1Z5q+nJjvg4Uu0xOAwDAyVFmcEKdk6PUKz1G1R5Dc1czERgA4L8oMzip2nvOvLNitwzDMDkNAAAnRpnBSY3ulaIwh03bDpRq1c4Cs+MAAHBClBmcVGSoQ6N6pkhiIjAAwH9RZnBKtROBP8nOVYmr2uQ0AAAcjzKDU+rfJlbtWkaorNKtj9fsMzsOAADHoczglCwWy08TgVdyqgkA4H8oMzita/qmyW61aPWuI/pxf7HZcQAAqIMyg9NqGenUJZ0TJUnvZ+41OQ0AAHVRZlAv1/atWd7gw9V75fZwzxkAgP+gzKBeLumcqOiwmsUnl247ZHYcAAC8KDOoF6fdptG9au4580EmyxsAAPwHZQb1dk3fNEnSZ+vyVMo9ZwAAfoIyg3rrkx6jdgkRKq9y67N1eWbHAQBAEmUGDWCxWHTN0YnAnGoCAPgLvy8ze/fu1a233qr4+HiFh4erd+/eWrVqldmxmq0xfWrKzNLth7T3SLnJaQAA8PMyU1BQoAsuuEAOh0OfffaZNmzYoL/+9a+KiYkxO1qzlRYbrvPaxckwai7TBgDAbHazA5zKH//4R6Wnp+u1117zbmvbtu0p3+NyueRyubzPi4qKGites3VN3zQt235YH2Tu0T1DzpHFYjE7EgCgGfPrIzPz5s1T//79df311ysxMVF9+vTRq6++esr3TJ06VdHR0d5Henp6E6VtPkZ0T1aow6ptB0q1dk+h2XEAAM2cX5eZ7du3a8aMGerQoYM+//xzTZgwQffdd5/efPPNk77n4YcfVmFhofexezeLI/paZKhDw7slS2IiMADAfBbDMPz23vQhISHq37+/lixZ4t123333acWKFVq6dGm9PqOoqEjR0dEqLCxUVFRUY0Vtdr7dckC3/Wu5YsMd+uGRyxRi9+teDAAIMA35++3Xf4FSUlLUtWvXOtu6dOmiXbt2mZQItS5on6DESKcKyqr09eZ8s+MAAJqxBpeZ+fPna/Hixd7nL730knr37q1bbrlFBQUFPg13wQUXaPPmzXW2bdmyRW3atPHpz0HD2awW/aIP95wBAJivwWXmd7/7nfcKoezsbP3mN7/RyJEjtX37dt1///0+DffrX/9ay5Yt07PPPqutW7dq9uzZmjlzpiZOnOjTn4MzU7u8wVeb8lVQWmlyGgBAc9XgMpOTk+M99fP+++/ryiuv1LPPPquXX35Zn332mU/DDRgwQHPnztXbb7+t7t2766mnntK0adM0duxYn/4cnJlOyZHqlhqlKrehj9fuMzsOAKCZanCZCQkJUVlZmSRp4cKFGjZsmCQpLi6uUe7pcuWVVyo7O1sVFRXauHGj7rzzTp//DJy52qMz72dyAz0AgDkaXGYGDx6s+++/X0899ZSWL1+uUaNGSaqZy5KWlubzgPBvV/VKlc1qUdbuI9p2oMTsOACAZqjBZWb69Omy2+167733NGPGDLVqVTMJ9LPPPtPw4cN9HhD+rWWkU0M6tpTERGAAgDn8+j4zvsB9ZhrfJ2tzNXF2plKjQ7X4wUtltbK8AQDg7DTqfWYyMzOVnZ3tff7f//5XY8aM0SOPPKLKSq5oaY6GdklUZKhd+wortCznkNlxAADNTIPLzN13360tW7ZIqllu4KabblJ4eLjeffddPfDAAz4PCP8X6rBpVI8USdJHa3JNTgMAaG4aXGa2bNmi3r17S5LeffddXXTRRZo9e7Zef/11vf/++77OhwAxuleqJGn+ulxVuT0mpwEANCcNLjOGYcjjqfljtXDhQo0cOVKSlJ6eroMHD/o2HQLGee3ildCiZnmD77fy7wEAoOk0uMz0799fTz/9tP79739r0aJF3kuzc3JylJSU5POACAw2q0Uje9SspD1vDTfQAwA0nQaXmWnTpikzM1OTJk3So48+qvbt20uS3nvvPZ1//vk+D4jAUXuqacH6/aqocpucBgDQXPjs0uyKigrZbDY5HA5ffJzPcGl20/F4DA3+41faV1ihV27tq+HdU8yOBAAIUI16aXatVatWadasWXrrrbeUmZmp0NBQvysyaFpWq8V7dIZTTQCApmJv6Bvy8/N14403atGiRYqJiZFhGCosLNQll1yiOXPmqGXLlo2REwFidK9U/ePb7fpyY76KK6oUGUrBBQA0rgYfmbn33ntVXFys9evX6/DhwyooKNC6detUVFSk++67rzEyIoB0S41Su5YRclV7tGDDfrPjAACagQaXmfnz52vGjBnq0qWLd1vXrl310ksv6bPPPvNpOAQei8WiqzjVBABoQg0uMx6P54RzYxwOh/f+M2jeasvM4h8P6nApS1wAABpXg8vMpZdeqsmTJ2vfvp/+X/fevXv161//WkOHDvVpOASmdi1bqHurKFV7DH2azfIGAIDG1eAyM336dBUXF6tt27Y655xz1L59e2VkZKi4uFgvvvhiY2REAOJUEwCgqTT4aqb09HRlZmZqwYIF2rRpkwzDUNeuXXXZZZc1Rj4EqCt7purZTzdpxY7Dyi0sV0p0mNmRAABBqsFlptbll1+uyy+/3Pt848aNGjVqlLZv3+6TYAhsqTFhGtA2Vit2FOjjNbm686J2ZkcCAASpM75p3s9VVlZq586dvvo4BAFONQEAmoLPygzwcyN7pMhmtSh7b6FyDpaaHQcAEKQoM2g08S2cuqB9giRpXhZHZwAAjYMyg0b106mmvfLRmqYAANRR7wnAsbGxslgsJ329urraJ4EQXK7olqRH5lq17UCpNuYWq2sqK5cDAHyr3mVm2rRpjRgDwSoy1KFLOyVq/vo8zVuzjzIDAPC5epeZ8ePHN2YOBLGreqdq/vo8fbRmnx4c3umUR/gAAGgo5syg0V3aOVEtnHbtPVKuzF0FZscBAAQZygwaXajDpmFdkyRxVRMAwPcoM2gSo3vXXNX0SXauqt2srg4A8B3KDJrE4PYJig136GBJpZZuP2R2HABAEKHMoEk4bFaN6JEiiVNNAADfqneZ6dq1qw4fPux9ftddd+nAgQPe5/n5+QoPD/dtOgSV2hvozV+fJ1e12+Q0AIBgUe8ys2nTpjo3xpszZ46Ki4u9zw3DUEVFhW/TIaic2zZOyVGhKq6o1jebD5z+DQAA1MMZn2Y60a3puX8ITsVqtejKnjWnmj5iJW0AgI8wZwZNavTRU01fbsxXWSVLYAAAzl69y4zFYjnuyAtHYtBQPdOi1SY+XOVVbi3YsN/sOACAIFDv5QwMw9DQoUNlt9e8pby8XKNHj1ZISIgkFppE/VgsFo3umarpX2/VR2tydXXvVmZHAgAEuHqXmccff7zO86uvvvq4fa699tqzT4Sgd1XvmjKzaEu+CsuqFB3uMDsSACCAnXGZAc5Ux6RIdUqK1Ob9xfp8fZ5uGJBudiQAQACr95yZiooKzZs3r87l2LWKioo0b948uVwun4ZD8Brd6+hVTWu5qgkAcHbqXWb+8Y9/6G9/+5siIyOPey0qKkovvviiXn31VZ+GQ/Cqvarp+60HdaCYEgwAOHP1LjNvvfWWpkyZctLXp0yZojfffNMXmdAMtImPUK+0aHkM6dPsXLPjAAACWL3LzI8//qhevXqd9PWePXvqxx9/9EkoNA+1R2e4gR4A4GzUu8xUV1fXWYvp5w4cOMDl2WiQ0b1SZbFIK3cWaO+RcrPjAAACVL3LTLdu3bRw4cKTvr5gwQJ169bNJ6HQPCRFhWpgRpwkjs4AAM5cvcvMHXfcoaeeekoff/zxca999NFHevrpp3XHHXf4NByC31W9am6aNy+LMgMAODP1vs/MXXfdpW+//VZXXXWVOnfurE6dOslisWjjxo3asmWLbrjhBt11112NmRVBaET3ZP3hv+u0IbdIW/NL1D6xhdmRAAABpkELTc6aNUtz5sxRx44dtWXLFm3atEmdOnXS22+/rbfffruxMiKIxUaE6KKOLSVJn6zlqiYAQMNZDMMwzA7RmIqKihQdHa3CwkJFRUWZHQcn8P6qPfrNu2vUMamFvvj1xWbHAQD4gYb8/a73aaZahw4dUnx8vCRp9+7devXVV72LTl500UVnlhjN2mVdkxRis2rL/hJt2V+sjknH35gRAICTqfdppuzsbLVt21aJiYnq3LmzsrKyNGDAAL3wwguaOXOmLr30Un344YeNGBXBKjrMoYs6JkiSPuZUEwCggepdZh544AH16NFDixYt0pAhQ3TllVdq5MiRKiwsVEFBge6++24999xzjZkVQWxUz5q1mj5Zu09BfuYTAOBj9Z4zk5CQoK+++ko9e/ZUSUmJoqKitHz5cvXv31+StGnTJp133nk6cuRIY+ZtMObMBIbiiir1e3qhKqs9mj/lQnVO5p8VADRnDfn7Xe8jM4cPH1ZycrIkqUWLFoqIiFBcXJz39djY2BOuqA3UR2SoQ0O4qgkAcAYadGm2xWI55XPgbNSeavp4bS6nmgAA9dagq5luv/12OZ1OSVJFRYUmTJigiIgISZLL5fJ9OjQrQ7skyWm3KudgqdbvK1L3VtFmRwIABIB6l5nx48fXeX7rrbcet89tt9129onQbLVw2nVJp0TNX5+nj9bso8wAAOql3mXmtddea8wc9TJ16lQ98sgjmjx5sqZNm2Z2HDSCMX1SNX99nv6btU8PDu8sq5VTmQCAU2vQnBkzrVixQjNnzlTPnj3NjoJGNKRToqJC7corqtCynENmxwEABICAKDMlJSUaO3asXn31VcXGxpodB40o1GHzTgT+cPVek9MAAAJBQJSZiRMnatSoUbrssstOu6/L5VJRUVGdBwLLmN6tJEmfZeeposptchoAgL/z+zIzZ84cZWZmaurUqfXaf+rUqYqOjvY+0tPTGzkhfG1A2zi1iglTsataX27MNzsOAMDP+XWZ2b17tyZPnqxZs2YpNDS0Xu95+OGHVVhY6H3s3r27kVPC16xWi67unSpJmsupJgDAafh1mVm1apXy8/PVr18/2e122e12LVq0SC+++KLsdrvc7uNPQTidTkVFRdV5IPCM6VNzqmnRlnwVlFaanAYA4M/8uswMHTpU2dnZysrK8j769++vsWPHKisrSzabzeyIaCQdkyLVNSVKVW5Dn2SzvAEA4OQadAfgphYZGanu3bvX2RYREaH4+PjjtiP4/KJPK23ILdKHq/fq1vPamB0HAOCn/PrIDJq3q3qnymKRVu4s0K5DZWbHAQD4Kb8+MnMi33zzjdkR0ESSokJ1wTkJWrz1oP6btVf3Du1gdiQAgB/iyAz8mveqpqy9rKQNADghygz82vDuyXLardp+oFTr9nIDRADA8Sgz8GuRoQ5d3jVJEvecAQCcGGUGfu8XR+85M2/NPlW7PSanAQD4G8oM/N5FHVsqNtyhgyUufb+NlbQBAHVRZuD3HDarRveqmQjMStoAgJ+jzCAgXH10Je3P1+eprLLa5DQAAH9CmUFA6Ns6Rq3jwlVW6dYX6/ebHQcA4EcoMwgIFovFu/jk+5l7TE4DAPAnlBkEjGv71pSZxVsPKrew3OQ0AAB/QZlBwGgTH6FzM+JkGNIHmUwEBgDUoMwgoFzXL02S9N6qPSxvAACQRJlBgBnZI0VhDptyDpYqc1eB2XEAAH6AMoOA0sJp18geKZJqjs4AAECZQcCpPdX00ZpclVe6TU4DADAbZQYBZ2BGnNJiw1Tiqtbn6/PMjgMAMBllBgHHarXUmQgMAGjeKDMISNf2rSkz3287qL1HuOcMADRnlBkEpPS4cJ3X7ug9Zzg6AwDNGmUGAev6fumSpPcyuecMADRnlBkErBE9khURYtPOQ2VasYN7zgBAc0WZQcAKDzn2njO7TU4DADALZQYB7fr+NaeaPlmbqxJXtclpAABmoMwgoA1oG6t2CREqrXTrv1ksPgkAzRFlBgHNYrHoloGtJUmzlu1iIjAANEOUGQS86/qlKcRu1cbcImXtPmJ2HABAE6PMIODFhIfoyp41E4FnLdtlchoAQFOjzCAo3HpeG0nSx2v36UhZpclpAABNiTKDoNAnPUZdUqLkqvawXhMANDOUGQQFi8WiW8+rmQj85tKdcnuYCAwAzQVlBkHjmj5pig13aNfhMs1fl2d2HABAE6HMIGiEhdg0blBbSdLMb7dxmTYANBOUGQSV8YPayGm3as2eQv2Qc9jsOACAJkCZQVCJb+HU9f3TJEn/WLTN5DQAgKZAmUHQ+eXgdrJYpK83H9CW/cVmxwEANDLKDIJO24QIDe+WLEma+e12k9MAABobZQZB6a6L2kmS/pu1V3mFFSanAQA0JsoMglKf1rE6t22cqtyGXluSY3YcAEAjoswgaN19cc3RmdnLdqm4osrkNACAxkKZQdC6pFOi2ie2ULGrWm8vZwFKAAhWlBkELavVorsurDk686/FO1RZ7TE5EQCgMVBmENSu7pOqxEin8ooq9NGafWbHAQA0AsoMgprTbtPtF7SVVHOZNkscAEDwocwg6I0d2EYRITZt3l+sb7YcMDsOAMDHKDMIetFhDt18bmtJ0sxF3EQPAIINZQbNwh2DM2S3WrR0+yFl7yk0Ow4AwIcoM2gWUmPCNLpXqiTpH9+yACUABBPKDJqNO49epv1pdq52HSozOQ0AwFcoM2g2uqZG6cIOCfIY0j8XM3cGAIIFZQbNyoSLz5Ek/WflHhWUVpqcBgDgC5QZNCvnnxOvbqlRKq9y642lO8yOAwDwAcoMmhWLxeI9OvPPxTkqLGMBSgAIdJQZNDujeqSoc3KkiiuqubIJAIIAZQbNjtVq0f2Xd5Qkvfb9Dh0odpmcCABwNigzaJYu75qkXukxKq9y629fbjE7DgDgLFBm0CxZLBY9PKKzJOnt5bv14/5ikxMBAM4UZQbN1nnt4nVFtyS5PYae+XSj2XEAAGeIMoNm7aERXeSwWfTN5gNaxIraABCQ/LrMTJ06VQMGDFBkZKQSExM1ZswYbd682exYCCIZCRG6bVBbSdIzn2xQtdtjbiAAQIP5dZlZtGiRJk6cqGXLlmnBggWqrq7WsGHDVFpaanY0BJH7Lu2gmHCHtuwv0X9W7jE7DgCggSyGYRhmh6ivAwcOKDExUYsWLdJFF110wn1cLpdcrp8utS0qKlJ6eroKCwsVFRXVVFERYF77Pkf/+9EGJbQI0de/HaLIUIfZkQCgWSsqKlJ0dHS9/n779ZGZnyssLJQkxcXFnXSfqVOnKjo62vtIT09vqngIYLee10btEiJ0sKRSM77hRnoAEEgC5siMYRi6+uqrVVBQoO++++6k+3FkBmdqwYb9uvPNlQqxW/XVby5WWmy42ZEAoNkKyiMzkyZN0tq1a/X222+fcj+n06moqKg6D6A+LuuSqEHt4lVZ7dHUzzaZHQcAUE8BUWbuvfdezZs3T19//bXS0tLMjoMgZbFY9NiVXWS1SJ+szdWCDfvNjgQAqAe/LjOGYWjSpEn64IMP9NVXXykjI8PsSAhy3VKjdedF7SRJj87NZlVtAAgAfl1mJk6cqFmzZmn27NmKjIxUXl6e8vLyVF5ebnY0BLFfX9ZR7VpGKL/Ypac+2WB2HADAafh1mZkxY4YKCws1ZMgQpaSkeB/vvPOO2dEQxEIdNv35ul6yWKT3Vu3Rkm0HzY4EADgFvy4zhmGc8HH77bebHQ1Brl+bWI0d2FqS9OjcdaqocpucCABwMn5dZgAzPTC8sxIjnco5WKrpX201Ow4A4CQoM8BJRIU69OTV3SRJryzapnV7C01OBAA4EcoMcArDu6doZI9kVXsMTZydqeIKrm4CAH9DmQFO49lf9FCrmDDtPFSmh97PVoDcNBsAmg3KDHAaMeEhmn5LH9mtFn2Snat/L9tpdiQAwDEoM0A99Gkdq4dGdJYkPf3xRmXvYf4MAPgLygxQT/8zOEOXd01SpdujibMzVcT8GQDwC5QZoJ4sFov+cl0vpcWGadfhMj3w7lrmzwCAH6DMAA0QHe7QS7f0lcNm0fz1eXpl0XazIwFAs0eZARqoV3qM/nBlV0nSnz7fpM/X55mcCACaN8oMcAbGDWqrcee1kWFIU+ZkcUM9ADARZQY4Q4+P7qoLOySovMqtO99cqfyiCrMjAUCzRJkBzpDdZtX0W/rqnJYRyi2s0J1vrlR5JQtSAkBTo8wAZyE6zKF/jh+gmHCH1uwp1L1vr1a122N2LABoVigzwFlqmxChmeP6K8Ru1cKN+/XQB9lye7hkGwCaCmUG8IFzM+L04k19ZLVI763ao8lzVquKIzQA0CQoM4CPDO+erOlH70Hz8dpc/WrWKlVUMYcGABobZQbwoZE9UjRzXH857VYt3Jiv/3ljhUpd1WbHAoCgRpkBfOySzol6/f+dq4gQm77feki3/Wu5CstZxwkAGgtlBmgEg86J16xfDlRUqF2rdhbolleX6VCJy+xYABCUKDNAI+nTOlZz7hqk+IgQrd9XpBtnLtN+bqwHAD5HmQEaUdfUKL1z9yAlR4Vqa36Jrn9lqbYdKDE7FgAEFcoM0MjaJ7bQuxMGKT0uTLsOl+nKFxfrPyt2yzC4Fw0A+AJlBmgC6XHhev9X5+uC9vEqr3LrgffX6t63V6uogonBAHC2KDNAE0mMDNW/7xioB4Z3ks1acy+akX/7Tqt2FpgdDQACGmUGaEJWq0X3DGmv946edtpTUK4b/rFUL329lSUQAOAMUWYAE/RpHatP7rtQV/VKldtj6M+fb9bY/1umnIOlZkcDgIBDmQFMEhXq0N9u6q2/XN9L4SE2Ldt+WFdM+1YvLNjCMggA0ACUGcBEFotF1/VL06f3XagLOySostqjv335o66Y9q2+2ZxvdjwACAiUGcAPtE2I0Jt3nKuXbumrpCindh4q0+2vrdCvZq1SbmG52fEAwK9RZgA/YbFYNKpnir78zRD9cnCGbFaLPluXp6F/XaSXv9nKgpUAcBIWI8jv3FVUVKTo6GgVFhYqKirK7DhAvW3YV6THPsxW5q4jkqS4iBD98sIM3TaorVo47eaGA4BG1pC/35QZwI95PIbmrt6rF7/6UTsPlUmSYsIduvPCdrptUBtFhjpMTggAjYMycwzKDIJBtduj/2bt0/Svt3ov3w4PsemqXqm66dzW6pUWLYvFYnJKAPAdyswxKDMIJm6PoY/W1JSarfk/LVjZOTlSNw1I1y/6pCk6nKM1AAIfZeYYlBkEI8MwtDznsOas2K1Ps3PlqvZIkpx2q0b2SNFNA9J1bkYcR2sABCzKzDEoMwh2hWVVmrt6j+as2K1NecXe7e0SIjSyR4ou75qkHq2iZbVSbAAEDsrMMSgzaC4Mw9CaPYWas3yX5q3Zp7LKn+4inBTl1GVdknR51yQNOideTrvNxKQAcHqUmWNQZtAclbiq9cX6PC3YsF+LthyoU2wiQmy6uFNLXdShpc5rF6828eGcjgLgdygzx6DMoLmrqHJr6bZD+mLDfi3cuF8Hil11Xk+KcmpgRrzOzYhT7/QYdUqOlMPG/TQBmIsycwzKDPATj8fQ2r2F+nLjfi3bfkhZu4+oyl33PwFOu1VdU6PUKy1GvdKj1SstRm3jI5hzA6BJUWaOQZkBTq6iyq3MXQX6YfthZe4q0JrdR1RUcfyyCZGhdnVJiVLXlCh1SYlUl5QodUyKVKiDuTcAGgdl5hiUGaD+DMPQjkNlWrP7iNbsOaK1ewq1bm+h99LvY9msFmUkRBwtOFHqnBKpcxJaqFVsmGwcxQFwligzx6DMAGenyu3Rj/tLtDG3qOaRV6SNucU6XFp5wv0dNovS48KVER+htgk1j4z4CLWJD1dydCjzcQDUS0P+frNaHYBTcthq5tB0Tf3pPyaGYSi/2KUNtQUnt1ibcou083CZKqs92n6gVNsPlB73WVaLlBQVqtSYMLWKCVOr2DClxoQp7ZjvWUQTQENxZAaAz3g8hvYVlmvHwTLlHCrVjoM1j5xDpdpzuFyV7uNPV/1cdJhDqTFhSo5yqmWkUwktTvC1hVNRYXYuKQeCGKeZjkGZAfyDx2PoYKlL+45UaG9BufYeKdO+IxXaU1CufUfKtfdIuQrLq+r9eSE2qxJahHgLzk9lJ0QtI0N/ei3SqUgnxQcINJxmAuB3rFaLEiNDlRgZqt7pMSfcp8RVXVNsCsqVX1yhA8UuHSyp1IES19Hva74WV1Sr0u3RvsIK7SusOO3PDrFbFRceophwh+IiQhQbEaK48BDFhjsUGxGi2PAQRYc5FBVmV1SoQ1FhDkWFOhTqsFKCgABAmQHgN1o47eqYFKmOSZGn3K+iyq1DpZU1BafYpQMlx3wtcelgcaV3W7GrWpXVHuUVVSiv6PTF51gOm0VRoQ5FhzkUGeZQVKjdW3QiQ+2KCLErwmlThNOu8BCbWjjtCg+x13x11j63KSLEzn16gEZEmQEQcEIdtpoJxDFhp923osqtgyUuHSmr0uHSShWUVdZ8La1UQVmVDpfVfF9cUa3C8ioVVVSpqLxKHkOqchs6VFqpQye5cqshwkNsR4uOrU7hiXDaFRFS+9Ve89Vp+1lRsnuLUe37WF8L+AllBkBQC3XYlBYbrrTY+r/HMAyVVrpV5C031Soqr/KWncLyKpW6qlXicqusslqlrmqVutwqPcH3nqOzEssq3SqrdOtgiW9+L4fNckwBsp2w8NQpSLWFyWlTqN0mp8OmUIdVTnvN11CHTaEOm5x2K5fPI+BQZgDgZywWi1o4a8pBqk5/9OdkDMOQq9qjEle1ylzumq+V1Ue/Hn3uqlbpMd/XFqTafUpd1UeLUc33tTcwrHIbOlJWpSNl9Z80XV82q0WhdmtN4bHXFB3n0aJTW3ycR7eHHi1Dtfs6jylFoScqTHabnA5rnfc57VY57cxPwpmjzABAI7FYLN4jHmrhm8+scnu8Jaem9LiPlqBjCtIx248tQrXfV1S55ar2qKKq5vuKao8qj7nLs9tTc2Sq9JjV1hubxaKjpcZWpzCF2K0KsdV8ddptNc/tVjm926zebSE223HbnEff73T89HpInW0/7V/7+dzBOvBQZgAggDhsVkWHWRUd5vDp53o8hirdnp8VnZ8/P+b7ao9cJ3vt5+87xb61p+EMQ0ff51FhuU9/tQazWS3HFChr3QL0s1J1wv2Oli2nw+Z9/ecF6tiy5f28o9vttpqf77DVfO+wWplAfhqUGQCArFaLQq22Jl081DAMVbkNVVS75fIWoJoy5Dq6zeWuOWrkOnr0qObh/un5Ma/X3eau+56ffY7r2M9xe3TsHdfcHkPlHrfKq5ruyNTp2KwWOWwWOY6WnBN9b7dZFWKzyG61ymGv+73jaCly2E/+GSd633GfUVuyrBaF2H/6Pjq85io/s1BmAACmsFgsCrHX/FFUqHk5DMNQtcfwFp+fSpG7bkk6phi5qt1193d75Kr6qTTVbHefvHCd4HMqqz2qchsnvFO222PI7TFUUXX6u2ibYcLF5+ihEZ1N+/mUGQBAs2ax/HTUI8JpdpqfylX10WJT7a4pOVVuz9HHyb+vdteUpNrvq9weVZ7k+2PfW/uzTvR9fd4XYjf3CriAKDMvv/yy/vznPys3N1fdunXTtGnTdOGFF5odCwAAn/upXElh4n5C9eH3NxN45513NGXKFD366KNavXq1LrzwQo0YMUK7du0yOxoAAPADfr/Q5MCBA9W3b1/NmDHDu61Lly4aM2aMpk6detr3s9AkAACBpyF/v/36yExlZaVWrVqlYcOG1dk+bNgwLVmy5ITvcblcKioqqvMAAADBy6/LzMGDB+V2u5WUlFRne1JSkvLy8k74nqlTpyo6Otr7SE9Pb4qoAADAJH5dZmr9/BbXhmGc9LbXDz/8sAoLC72P3bt3N0VEAABgEr++mikhIUE2m+24ozD5+fnHHa2p5XQ65XT6wbV1AACgSfj1kZmQkBD169dPCxYsqLN9wYIFOv/8801KBQAA/IlfH5mRpPvvv1/jxo1T//79NWjQIM2cOVO7du3ShAkTzI4GAAD8gN+XmRtvvFGHDh3Sk08+qdzcXHXv3l2ffvqp2rRpY3Y0AADgB/z+PjNni/vMAAAQeILmPjMAAACnQ5kBAAABjTIDAAACGmUGAAAENL+/muls1c5vZo0mAAACR+3f7fpcpxT0Zaa4uFiSWKMJAIAAVFxcrOjo6FPuE/SXZns8Hu3bt0+RkZEnXc/pTBUVFSk9PV27d+/msu9GxDg3Dca5aTDOTYexbhqNNc6GYai4uFipqamyWk89Kyboj8xYrValpaU16s+IiorifyhNgHFuGoxz02Ccmw5j3TQaY5xPd0SmFhOAAQBAQKPMAACAgEaZOQtOp1OPP/64nE6n2VGCGuPcNBjnpsE4Nx3Gumn4wzgH/QRgAAAQ3DgyAwAAAhplBgAABDTKDAAACGiUGQAAENAoM2fo5ZdfVkZGhkJDQ9WvXz999913ZkcKKFOnTtWAAQMUGRmpxMREjRkzRps3b66zj2EYeuKJJ5SamqqwsDANGTJE69evr7OPy+XSvffeq4SEBEVEROiqq67Snj17mvJXCRhTp06VxWLRlClTvNsYY9/Zu3evbr31VsXHxys8PFy9e/fWqlWrvK8z1mevurpajz32mDIyMhQWFqZ27drpySeflMfj8e7DOJ+Zb7/9VqNHj1ZqaqosFos+/PDDOq/7alwLCgo0btw4RUdHKzo6WuPGjdORI0fO/hcw0GBz5swxHA6H8eqrrxobNmwwJk+ebERERBg7d+40O1rAuOKKK4zXXnvNWLdunZGVlWWMGjXKaN26tVFSUuLd57nnnjMiIyON999/38jOzjZuvPFGIyUlxSgqKvLuM2HCBKNVq1bGggULjMzMTOOSSy4xevXqZVRXV5vxa/mt5cuXG23btjV69uxpTJ482budMfaNw4cPG23atDFuv/1244cffjBycnKMhQsXGlu3bvXuw1ifvaefftqIj483Pv74YyMnJ8d49913jRYtWhjTpk3z7sM4n5lPP/3UePTRR43333/fkGTMnTu3zuu+Gtfhw4cb3bt3N5YsWWIsWbLE6N69u3HllVeedX7KzBk499xzjQkTJtTZ1rlzZ+Ohhx4yKVHgy8/PNyQZixYtMgzDMDwej5GcnGw899xz3n0qKiqM6Oho45VXXjEMwzCOHDliOBwOY86cOd599u7da1itVmP+/PlN+wv4seLiYqNDhw7GggULjIsvvthbZhhj33nwwQeNwYMHn/R1xto3Ro0aZdxxxx11tl1zzTXGrbfeahgG4+wrPy8zvhrXDRs2GJKMZcuWefdZunSpIcnYtGnTWWXmNFMDVVZWatWqVRo2bFid7cOGDdOSJUtMShX4CgsLJUlxcXGSpJycHOXl5dUZZ6fTqYsvvtg7zqtWrVJVVVWdfVJTU9W9e3f+WRxj4sSJGjVqlC677LI62xlj35k3b5769++v66+/XomJierTp49effVV7+uMtW8MHjxYX375pbZs2SJJWrNmjRYvXqyRI0dKYpwbi6/GdenSpYqOjtbAgQO9+5x33nmKjo4+67EP+oUmfe3gwYNyu91KSkqqsz0pKUl5eXkmpQpshmHo/vvv1+DBg9W9e3dJ8o7licZ5586d3n1CQkIUGxt73D78s6gxZ84cZWZmasWKFce9xhj7zvbt2zVjxgzdf//9euSRR7R8+XLdd999cjqduu222xhrH3nwwQdVWFiozp07y2azye1265lnntHNN98siX+nG4uvxjUvL0+JiYnHfX5iYuJZjz1l5gxZLJY6zw3DOG4b6mfSpElau3atFi9efNxrZzLO/LOosXv3bk2ePFlffPGFQkNDT7ofY3z2PB6P+vfvr2effVaS1KdPH61fv14zZszQbbfd5t2PsT4777zzjmbNmqXZs2erW7duysrK0pQpU5Samqrx48d792OcG4cvxvVE+/ti7DnN1EAJCQmy2WzHtcj8/PzjWitO795779W8efP09ddfKy0tzbs9OTlZkk45zsnJyaqsrFRBQcFJ92nOVq1apfz8fPXr1092u112u12LFi3Siy++KLvd7h0jxvjspaSkqGvXrnW2denSRbt27ZLEv8++8rvf/U4PPfSQbrrpJvXo0UPjxo3Tr3/9a02dOlUS49xYfDWuycnJ2r9//3Gff+DAgbMee8pMA4WEhKhfv35asGBBne0LFizQ+eefb1KqwGMYhiZNmqQPPvhAX331lTIyMuq8npGRoeTk5DrjXFlZqUWLFnnHuV+/fnI4HHX2yc3N1bp16/hnIWno0KHKzs5WVlaW99G/f3+NHTtWWVlZateuHWPsIxdccMFxtxbYsmWL2rRpI4l/n32lrKxMVmvdP1s2m817aTbj3Dh8Na6DBg1SYWGhli9f7t3nhx9+UGFh4dmP/VlNH26mai/N/uc//2ls2LDBmDJlihEREWHs2LHD7GgB41e/+pURHR1tfPPNN0Zubq73UVZW5t3nueeeM6Kjo40PPvjAyM7ONm6++eYTXgqYlpZmLFy40MjMzDQuvfTSZn+J5akcezWTYTDGvrJ8+XLDbrcbzzzzjPHjjz8ab731lhEeHm7MmjXLuw9jffbGjx9vtGrVyntp9gcffGAkJCQYDzzwgHcfxvnMFBcXG6tXrzZWr15tSDKef/55Y/Xq1d5bjvhqXIcPH2707NnTWLp0qbF06VKjR48eXJptppdeeslo06aNERISYvTt29d7STHqR9IJH6+99pp3H4/HYzz++ONGcnKy4XQ6jYsuusjIzs6u8znl5eXGpEmTjLi4OCMsLMy48sorjV27djXxbxM4fl5mGGPf+eijj4zu3bsbTqfT6Ny5szFz5sw6rzPWZ6+oqMiYPHmy0bp1ayM0NNRo166d8eijjxoul8u7D+N8Zr7++usT/jd5/PjxhmH4blwPHTpkjB071oiMjDQiIyONsWPHGgUFBWed32IYhnF2x3YAAADMw5wZAAAQ0CgzAAAgoFFmAABAQKPMAACAgEaZAQAAAY0yAwAAAhplBgAABDTKDAAACGiUGQDNjsVi0Ycffmh2DAA+QpkB0KRuv/12WSyW4x7Dhw83OxqAAGU3OwCA5mf48OF67bXX6mxzOp0mpQEQ6DgyA6DJOZ1OJScn13nExsZKqjkFNGPGDI0YMUJhYWHKyMjQu+++W+f92dnZuvTSSxUWFqb4+HjdddddKikpqbPPv/71L3Xr1k1Op1MpKSmaNGlSndcPHjyoX/ziFwoPD1eHDh00b968xv2lATQaygwAv/P73/9e1157rdasWaNbb71VN998szZu3ChJKisr0/DhwxUbG6sVK1bo3Xff1cKFC+uUlRkzZmjixIm66667lJ2drXnz5ql9+/Z1fsb//u//6oYbbtDatWs1cuRIjR07VocPH27S3xOAj5z1utsA0ADjx483bDabERERUefx5JNPGoZhGJKMCRMm1HnPwIEDjV/96leGYRjGzJkzjdjYWKOkpMT7+ieffGJYrVYjLy/PMAzDSE1NNR599NGTZpBkPPbYY97nJSUlhsViMT777DOf/Z4Amg5zZgA0uUsuuUQzZsyosy0uLs77/aBBg+q8NmjQIGVlZUmSNm7cqF69eikiIsL7+gUXXCCPx6PNmzfLYrFo3759Gjp06Ckz9OzZ0/t9RESEIiMjlZ+ff6a/EgATUWYANLmIiIjjTvucjsVikSQZhuH9/kT7hIWF1evzHA7Hce/1eDwNygTAPzBnBoDfWbZs2XHPO3fuLEnq2rWrsrKyVFpa6n39+++/l9VqVceOHRUZGam2bdvqyy+/bNLMAMzDkRkATc7lcikvL6/ONrvdroSEBEnSu+++q/79+2vw4MF66623tHz5cv3zn/+UJI0dO1aPP/64xo8fryeeeEIHDhzQvffeq3HjxikpKUmS9MQTT2jChAlKTEzUiBEjVFxcrO+//1733ntv0/6iAJoEZQZAk5s/f75SUlLqbOvUqZM2bdokqeZKozlz5uiee+5RcnKy3nrrLXXt2lWSFB4ers8//1yTJ0/WgAEDFB4ermuvvVbPP/+897PGjx+viooKvfDCC/rtb3+rhIQEXXfddU33CwJoUhbDMAyzQwBALYvForlz52rMmDFmRwEQIJgzAwAAAhplBgAABDTmzADwK5z5BtBQHJkBAAABjTIDAAACGmUGAAAENMoMAAAIaJQZAAAQ0CgzAAAgoFFmAABAQKPMAACAgPb/ATgwHTRftVnFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_model_128, label=\"128\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BCE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd464f5e",
   "metadata": {},
   "source": [
    "#### Recommendations with the trained Factorization Model\n",
    "Write a function that recommends topK items to a user, whose id is given, using the trained model.\n",
    "Recommendation should be done in a fashion similar to *svd_recommend*: score items based the corresponding embeddings. Do not consider items already seen by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a2df714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itMF_recommend(user_id: int, seen_item_ids: list, model=None, topK: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Recommend with the trained model to selected users\n",
    "    \n",
    "    user_id - int, id of target user;\n",
    "    seen_item_ids - list[list[int]], ids of items already seen by the users (to exclude from recommendation);\n",
    "    model - trained factorization model to use for scoring;\n",
    "    topK - int, number of recommendations per user to be returned;\n",
    "    \n",
    "    returns - 1D np.ndarray, list of ids of recommended items in the order of descending score\n",
    "                           use -1 as a place holder item index, when it is impossible to recommend topK items;\n",
    "    \"\"\"\n",
    "    recs = None\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "\n",
    "    all_item_ids = torch.arange(model.embedding_item.num_embeddings, dtype=torch.long)\n",
    "    user_tensor  = torch.tensor([user_id], dtype=torch.long)  # shape: (1,)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(user_tensor, all_item_ids) \n",
    "        scores = logits.squeeze(0)\n",
    "\n",
    "    scores[seen_item_ids] = float('-inf')\n",
    "\n",
    "    ranked_items = torch.argsort(scores, descending=True)\n",
    "\n",
    "    top_k_items = ranked_items[:topK].cpu().numpy()\n",
    "\n",
    "    if len(top_k_items) < topK:\n",
    "        top_k_items = np.concatenate([top_k_items, np.full(topK - len(top_k_items), -1)])\n",
    "\n",
    "    recs = top_k_items\n",
    "\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f534cd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 85, 167,  30,   3, 117,  64, 348, 282, 286, 269])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 5\n",
    "seen_list = np.where(train_data_inter[user_id] != 0)\n",
    "\n",
    "itMF_recommend(user_id, seen_list, model_128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9d856ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmwTeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
