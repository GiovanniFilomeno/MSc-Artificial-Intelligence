{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4HqV9NYTy1x-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4HqV9NYTy1x-",
        "outputId": "c223122e-cce5-42e2-d86a-c5cf2e2f011e"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T9g6XaRlzzNU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9g6XaRlzzNU",
        "outputId": "7032683f-d872-4670-fdaf-10d954b90d0c"
      },
      "outputs": [],
      "source": [
        "!pip install rdkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4d8cf2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4d8cf2d",
        "outputId": "553136fb-f17f-444a-c8db-406b0cfe47fa"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random, numpy as np, torch\n",
        "from rdkit import Chem, RDLogger\n",
        "\n",
        "RDLogger.DisableLog('rdApp.*')      \n",
        "\n",
        "TRAIN_FILE = 'train.txt'\n",
        "\n",
        "with open(TRAIN_FILE) as f:\n",
        "    smiles_list = [s.strip() for s in f if s.strip()]\n",
        "\n",
        "print(f'Training molecules: {len(smiles_list):,}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a2efb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56a2efb3",
        "outputId": "3f84a629-04d7-4817-a441-7c8be0209e2f"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, smiles, bos='$', eos='^', pad='&'):\n",
        "        self.bos, self.eos, self.pad = bos, eos, pad\n",
        "        tokens = set([bos, eos, pad])\n",
        "        for s in smiles: tokens.update(list(s))\n",
        "        self.idx2tok = sorted(tokens)\n",
        "        self.tok2idx = {t:i for i,t in enumerate(self.idx2tok)}\n",
        "\n",
        "    def encode(self, s, max_len):\n",
        "        s = self.bos + s + self.eos\n",
        "        s += self.pad*(max_len-len(s))\n",
        "        return [self.tok2idx[c] for c in s]\n",
        "\n",
        "    def decode(self, idxs):\n",
        "        toks = [self.idx2tok[i] for i in idxs]\n",
        "        s = ''.join(toks).split(self.eos)[0]       # cut EOS\n",
        "        return s.replace(self.bos,'').replace(self.pad,'')\n",
        "\n",
        "vocab    = Vocabulary(smiles_list)\n",
        "MAX_LEN  = max(len(s) for s in smiles_list)+2     # + BOS/EOS\n",
        "\n",
        "print('Vocab size:', len(vocab.idx2tok))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34804da7",
      "metadata": {
        "id": "34804da7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SmilesDataset(Dataset):\n",
        "    def __init__(self, smiles, vocab, max_len):\n",
        "        self.smiles = smiles\n",
        "        self.vocab  = vocab\n",
        "        self.max_len= max_len\n",
        "\n",
        "    def __len__(self): return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq  = torch.tensor(self.vocab.encode(self.smiles[idx], self.max_len))\n",
        "        inp  = seq[:-1]           # remove last token\n",
        "        targ = seq[1:]            # left shift\n",
        "        return inp.long(), targ.long()\n",
        "\n",
        "BATCH = 512\n",
        "ds    = SmilesDataset(smiles_list, vocab, MAX_LEN)\n",
        "dl    = DataLoader(ds, batch_size=BATCH, shuffle=True, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46899f65",
      "metadata": {
        "id": "46899f65"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "class SmilesLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, hid_dim=512, n_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.emb   = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.lstm  = nn.LSTM(emb_dim, hid_dim, n_layers,\n",
        "                             batch_first=True, dropout=dropout)\n",
        "        self.fc    = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        out, h = self.lstm(self.emb(x), h)\n",
        "        logits = self.fc(out)\n",
        "        return logits, h\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, max_len, temperature=1.0, canonical=True):\n",
        "        bos = torch.tensor([[vocab.tok2idx[vocab.bos]]], device=self.fc.weight.device)\n",
        "        out, h = self.forward(bos)\n",
        "        idx    = bos\n",
        "        gen    = []\n",
        "        for _ in range(max_len-1):\n",
        "            logits = out[:,-1,:]/temperature\n",
        "            p      = F.softmax(logits, -1)\n",
        "            idx    = torch.multinomial(p, 1)\n",
        "            token  = idx.item()\n",
        "            if token == vocab.tok2idx[vocab.eos]: break\n",
        "            gen.append(token)\n",
        "            out, h = self.forward(idx, h)\n",
        "        smi = vocab.decode(gen)\n",
        "        if not canonical: return smi\n",
        "        try:                             # canonicalizza\n",
        "            return Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
        "        except: return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "585fc01d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "585fc01d",
        "outputId": "d7753853-abab-4d11-a87c-65639dceaf59"
      },
      "outputs": [],
      "source": [
        "import random, torch, numpy as np\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "device   = torch.device('cuda')  \n",
        "\n",
        "# --------------- DATASET + VALIDATION SPLIT ---------------\n",
        "VAL_FRAC = 0.05\n",
        "val_len  = int(len(ds) * VAL_FRAC)\n",
        "train_len= len(ds) - val_len\n",
        "train_ds, val_ds = random_split(ds, [train_len, val_len],\n",
        "                                generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
        "                      num_workers=0, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False,\n",
        "                      num_workers=0, pin_memory=True)\n",
        "\n",
        "# --------------- MODEL, OPTIM, SCHEDULER ---------------\n",
        "model = SmilesLSTM(len(vocab.idx2tok),\n",
        "                   emb_dim=128,      \n",
        "                   hid_dim=512,     \n",
        "                   n_layers=2,\n",
        "                   dropout=0.3).to(device)\n",
        "opt    = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "crit   = torch.nn.CrossEntropyLoss(ignore_index=vocab.tok2idx[vocab.pad])\n",
        "\n",
        "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=2, factor=0.5)\n",
        "\n",
        "\n",
        "# --------------- TRAIN LOOP con EARLY-STOP ---------------\n",
        "EPOCHS     = 50\n",
        "LOG_EVERY  = 100\n",
        "PATIENCE   = 5           # early stop\n",
        "best_val   = float('inf')\n",
        "stall      = 0\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    # --------------- TRAIN ---------------\n",
        "    model.train(); tot=0; n=0\n",
        "    for i,(x,y) in enumerate(train_dl,1):\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits,_ = model(x)\n",
        "        loss = crit(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "        opt.step()\n",
        "        tot += loss.item(); n += 1\n",
        "\n",
        "        if i % LOG_EVERY == 0:\n",
        "            model.eval()\n",
        "\n",
        "            raw = model.sample(MAX_LEN, temperature=0.8, canonical=False)\n",
        "\n",
        "            can = model.sample(MAX_LEN, temperature=0.8, canonical=True)\n",
        "            valid = can is not None           # True/False\n",
        "\n",
        "            print(f'E{ep:02d} B{i:05d}/{len(train_dl)}  '\n",
        "                  f'train-loss {loss.item():.3f}  '\n",
        "                  f'raw: {raw}  '\n",
        "                  f'can: {can}  '\n",
        "                  f'valid: {valid}')\n",
        "\n",
        "            model.train()\n",
        "\n",
        "\n",
        "    train_loss = tot / n\n",
        "\n",
        "    # --------------- VALIDATION ---------------\n",
        "    model.eval(); vtot=0; vn=0\n",
        "    with torch.no_grad():\n",
        "        for x,y in val_dl:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            logits,_ = model(x)\n",
        "            vloss = crit(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "            vtot += vloss.item(); vn += 1\n",
        "    val_loss = vtot / vn\n",
        "    print(f'>> Epoch {ep:02d}  train {train_loss:.4f} | val {val_loss:.4f}')\n",
        "\n",
        "    # --------------- SCHEDULER & EARLY-STOP ---------------\n",
        "    sched.step(val_loss)    \n",
        "\n",
        "    if val_loss < best_val - 1e-4:     # floating\n",
        "        best_val = val_loss\n",
        "        stall = 0\n",
        "        torch.save(model.state_dict(), 'lstm_best_colab.pth')\n",
        "        print('   âœ“ new best model saved')\n",
        "    else:\n",
        "        stall += 1\n",
        "        print(f'   no improvement ({stall}/{PATIENCE})')\n",
        "        if stall >= PATIENCE:\n",
        "            print('*** Early stopping ***')\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3baa7ecc",
      "metadata": {
        "id": "3baa7ecc",
        "outputId": "95849f25-ec08-4a68-d11c-33eb8ec22de4"
      },
      "outputs": [],
      "source": [
        "# --------------- LOAD BEST ---------------\n",
        "model = SmilesLSTM(len(vocab.idx2tok),\n",
        "                   emb_dim=128,  \n",
        "                   hid_dim=512,   \n",
        "                   n_layers=2,\n",
        "                   dropout=0.3).to(device)\n",
        "model.load_state_dict(torch.load('lstm_best_colab.pth'))\n",
        "model.eval()\n",
        "\n",
        "N_GEN = 10_000\n",
        "counter = 0\n",
        "gen   = []\n",
        "while len(gen) < N_GEN:\n",
        "    smi = model.sample(MAX_LEN, temperature=0.95)  \n",
        "    counter = counter + 1\n",
        "    if smi and smi not in gen:\n",
        "        gen.append(smi)\n",
        "        if len(gen) % 10 == 0:\n",
        "            print(f\"Generated {len(gen)} valid unique SMILES after {counter} total attempts\")\n",
        "\n",
        "SUB_FILE = Path('submission_colab.txt')\n",
        "SUB_FILE.write_text('\\n'.join(gen))\n",
        "print('Saved', SUB_FILE, 'with', len(gen), 'SMILES')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70b0d72e",
      "metadata": {
        "id": "70b0d72e",
        "outputId": "b5f11b71-2b73-4b9f-8e6a-e08d7384faac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e82e87",
      "metadata": {
        "id": "c2e82e87"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
