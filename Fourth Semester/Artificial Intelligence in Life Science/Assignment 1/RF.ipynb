{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Tuning per task7 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:48:42] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:48:42] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:48:42] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:48:42] WARNING: not removing hydrogen atom without neighbors\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('entropy'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point ['balanced', 'gini', 17, 0.7, np.int64(9), np.int64(8), np.int64(2382)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'gini', 8, 'sqrt', np.int64(7), np.int64(13), np.int64(2309)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point ['balanced', 'entropy', 19, 0.7, np.int64(4), np.int64(5), np.int64(1213)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point ['balanced', 'entropy', 35, 'sqrt', np.int64(10), np.int64(5), np.int64(2438)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'entropy', 30, 0.7, np.int64(9), np.int64(13), np.int64(649)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(8), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'gini', 31, 0.5, np.int64(7), np.int64(9), np.int64(1891)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(24), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'entropy', 29, 0.7, np.int64(3), np.int64(11), np.int64(556)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(24), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'gini', 7, 'sqrt', np.int64(2), np.int64(10), np.int64(352)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(24), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point [None, 'entropy', 20, 0.5, np.int64(6), np.int64(6), np.int64(2017)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(24), np.str_('log2'), np.int64(1), np.int64(2), np.int64(2500)] before, using random point ['balanced', 'gini', 20, 'log2', np.int64(2), np.int64(13), np.int64(1131)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(13), np.str_('log2'), np.int64(1), np.int64(2), np.int64(1250)] before, using random point ['balanced', 'gini', 25, 0.5, np.int64(6), np.int64(9), np.int64(1990)]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [np.str_('balanced'), np.str_('gini'), np.int64(13), np.str_('log2'), np.int64(1), np.int64(2), np.int64(1247)] before, using random point ['balanced', 'entropy', 30, 'log2', np.int64(2), np.int64(8), np.int64(298)]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# grid_search = GridSearchCV(\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#     estimator=rf,\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m#     param_grid=param_grid,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#     random_state=42 # Aggiungi per riproducibilità della ricerca casuale\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    108\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m BayesSearchCV(\n\u001b[1;32m    109\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf,\n\u001b[1;32m    110\u001b[0m     search_spaces\u001b[38;5;241m=\u001b[39msearch_spaces, \u001b[38;5;66;03m# Usa gli spazi definiti sopra\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m            \u001b[38;5;66;03m# Per riproducibilità della ricerca\u001b[39;00m\n\u001b[1;32m    116\u001b[0m )\n\u001b[0;32m--> 117\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_f, y_train_f)\n\u001b[1;32m    119\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step(\n\u001b[1;32m    600\u001b[0m         search_space,\n\u001b[1;32m    601\u001b[0m         optimizer,\n\u001b[1;32m    602\u001b[0m         score_name,\n\u001b[1;32m    603\u001b[0m         evaluate_candidates,\n\u001b[1;32m    604\u001b[0m         n_points\u001b[38;5;241m=\u001b[39mn_points_adjusted,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/searchcv.py:445\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask(n_points\u001b[38;5;241m=\u001b[39mn_points)\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[1;32m    448\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:464\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         opt\u001b[38;5;241m.\u001b[39m_tell(x, (y_lie, t_lie))\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         opt\u001b[38;5;241m.\u001b[39m_tell(x, y_lie)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_ \u001b[38;5;241m=\u001b[39m {(n_points, strategy): X}  \u001b[38;5;66;03m# cache_ the result\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/optimizer/optimizer.py:615\u001b[0m, in \u001b[0;36mOptimizer._tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    614\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 615\u001b[0m     est\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspace\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mXi), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myi)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_xs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_hedge\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgains_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_xs_))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/skopt/learning/gaussian_process/gpr.py:203\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m+\u001b[39m WhiteKernel(\n\u001b[1;32m    201\u001b[0m             noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise, noise_level_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         )\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# The noise component of this kernel should be set to zero\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# while estimating K(X_test, X_test)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# http://www.gaussianprocess.org/gpml/chapters/RW2.pdf\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Hence this hack\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:326\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[1;32m    324\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    325\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 326\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constrained_optimization(obj_func, theta_initial, bounds)\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[1;32m    330\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:653\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 653\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(\n\u001b[1;32m    654\u001b[0m             obj_func,\n\u001b[1;32m    655\u001b[0m             initial_theta,\n\u001b[1;32m    656\u001b[0m             method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    657\u001b[0m             jac\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    658\u001b[0m             bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m    659\u001b[0m         )\n\u001b[1;32m    660\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    661\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    739\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_if_needed(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/scipy/optimize/_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun(x, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:298\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 298\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(\n\u001b[1;32m    299\u001b[0m             theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    300\u001b[0m         )\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:577\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    574\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 577\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    579\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:864\u001b[0m, in \u001b[0;36mSum.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the kernel k(X, Y) and optionally its gradient.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03m    is True.\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 864\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    865\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk2(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m+\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack((K1_gradient, K2_gradient))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/retina/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:963\u001b[0m, in \u001b[0;36mProduct.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m    962\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 963\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk2(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m*\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack(\n\u001b[1;32m    965\u001b[0m         (K1_gradient \u001b[38;5;241m*\u001b[39m K2[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], K2_gradient \u001b[38;5;241m*\u001b[39m K1[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis])\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from joblib import dump\n",
    "\n",
    "# 1) Leggi dataset, mappa -1->0, +1->1, 0->NaN\n",
    "df = pd.read_csv(\"data/data_train.csv\")\n",
    "task_cols = [f\"task{i}\" for i in range(1,12)]\n",
    "\n",
    "for c in task_cols:\n",
    "    df[c] = df[c].map({\n",
    "        -1: 0,\n",
    "        1: 1,\n",
    "        0: np.nan\n",
    "    })\n",
    "\n",
    "# 2) Funzione fingerprint\n",
    "def smiles_to_fp(smiles, nBits=1024, radius=2):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(nBits, dtype=np.uint8)\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
    "    fp = fpgen.GetFingerprint(mol)\n",
    "    arr = np.zeros((nBits,), dtype=np.uint8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    return arr\n",
    "\n",
    "# 3) Costruisci fingerprint per tutti\n",
    "X = np.array([smiles_to_fp(s) for s in df[\"smiles\"]], dtype=np.float32)\n",
    "\n",
    "# 4) Unico split train/test\n",
    "df_train, df_test, X_train, X_test = train_test_split(df, X, test_size=0.05, random_state=42)\n",
    "\n",
    "# Parametri di esempio per la ricerca\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 5, 10]\n",
    "#     # puoi aggiungere 'min_samples_split': [2, 5] ecc.\n",
    "# }\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [5, 10, 20, 50, 100, 200, 300, 500, 700, 1000],  # Numero di alberi nella foresta\n",
    "#     'criterion': ['gini', 'entropy'],         # Funzione per misurare la qualità di uno split (per classificazione)\n",
    "#                                               # Se fai regressione, usa: ['squared_error', 'absolute_error']\n",
    "#     'max_depth': [None, 1, 3, 5, 10, 20, 22, 27, 30],       # Massima profondità di ciascun albero (None = nodi espansi finché puri o min_samples_split)\n",
    "#     'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],          # Numero minimo di campioni richiesti per splittare un nodo interno\n",
    "#     'min_samples_leaf': [1, 3, 5, 6, 7],           # Numero minimo di campioni richiesti in un nodo foglia\n",
    "#     'max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "#     'class_weight': [None, 'balanced'] \n",
    "# }\n",
    "\n",
    "search_spaces = {\n",
    "    'n_estimators': Integer(5, 2500),  # Range intero (limiti inclusi)\n",
    "    'criterion': Categorical(['gini', 'entropy']), # Valori discreti\n",
    "    'max_depth': Categorical([None, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35]), # Valori discreti, incluso None e range affinato\n",
    "    'min_samples_split': Integer(2, 15), # Range intero\n",
    "    'min_samples_leaf': Integer(1, 10),  # Range intero\n",
    "    'max_features': Categorical(['sqrt', 'log2', 0.5, 0.7]), # Valori discreti (manteniamo questo semplice per ora)\n",
    "    # Nota: Si potrebbe usare Real(0.1, 1.0) per max_features, ma gestire misto float/string è più complesso.\n",
    "    # Mantenere Categorical con i valori che hanno funzionato è ragionevole.\n",
    "    'class_weight': Categorical([None, 'balanced']) # Valori discreti\n",
    "}\n",
    "\n",
    "auc_list = []\n",
    "\n",
    "for i, task in enumerate(task_cols[6:], start=7):\n",
    "    print(f\"\\n*** Tuning per {task} ***\")\n",
    "    # a) Seleziona i sample definiti per training\n",
    "    train_mask = ~df_train[task].isna()\n",
    "    X_train_f = X_train[train_mask]\n",
    "    y_train_f = df_train.loc[train_mask, task].values.astype(int)\n",
    "\n",
    "    if len(y_train_f) == 0:\n",
    "        print(f\"Nessun sample train per {task}, skip.\")\n",
    "        continue\n",
    "\n",
    "    # b) Esegui una Grid Search\n",
    "    rf = RandomForestClassifier(random_state=0)  \n",
    "    # grid_search = GridSearchCV(\n",
    "    #     estimator=rf,\n",
    "    #     param_grid=param_grid,\n",
    "    #     scoring='roc_auc', # ottimizziamo AUC\n",
    "    #     cv=3,              # 3-fold cross validation\n",
    "    #     n_jobs=-1\n",
    "    # )\n",
    "\n",
    "    # grid_search = RandomizedSearchCV(\n",
    "    #     estimator=rf,\n",
    "    #     param_distributions=param_grid, # Nota: per RandomizedSearchCV si chiama param_distributions\n",
    "    #     n_iter=1000,                     # <<< AGGIUNGI QUESTO! Numero di combinazioni da provare\n",
    "    #     scoring='roc_auc',\n",
    "    #     cv=5,\n",
    "    #     n_jobs=-1,\n",
    "    #     random_state=42 # Aggiungi per riproducibilità della ricerca casuale\n",
    "    # )\n",
    "    grid_search = BayesSearchCV(\n",
    "        estimator=rf,\n",
    "        search_spaces=search_spaces, # Usa gli spazi definiti sopra\n",
    "        n_iter=400,       # Numero di combinazioni da provare\n",
    "        scoring='roc_auc',\n",
    "        cv=5,                      # CONSIGLIATO: 5-fold CV\n",
    "        n_jobs=-1,\n",
    "        random_state=42            # Per riproducibilità della ricerca\n",
    "    )\n",
    "    grid_search.fit(X_train_f, y_train_f)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best params for {task}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Salvataggio del modello\n",
    "    dump(best_model, f\"rf_task{i}.joblib\")\n",
    "    print(f\"Salvato: rf_task{i}.joblib\")\n",
    "\n",
    "    # c) Valutazione su test\n",
    "    test_mask = ~df_test[task].isna()\n",
    "    X_test_f = X_test[test_mask]\n",
    "    y_test_f = df_test.loc[test_mask, task].values.astype(int)\n",
    "\n",
    "    if len(y_test_f) == 0:\n",
    "        print(f\"Nessun sample test per {task}, skip.\")\n",
    "        continue\n",
    "\n",
    "    # Predici prob\n",
    "    y_proba = best_model.predict_proba(X_test_f)[:, 1]  # output continuo\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    precision = precision_score(y_test_f, y_pred, zero_division=0)\n",
    "    if len(np.unique(y_test_f)) == 2:\n",
    "        auc_val = roc_auc_score(y_test_f, y_proba)\n",
    "    else:\n",
    "        auc_val = np.nan\n",
    "\n",
    "    print(f\"{task} -> Precision={precision:.3f}, AUC={auc_val if not np.isnan(auc_val) else 'N/A'}\")\n",
    "    auc_list.append(auc_val)\n",
    "\n",
    "valid_aucs = [x for x in auc_list if not np.isnan(x)]\n",
    "mean_auc = np.mean(valid_aucs) if valid_aucs else np.nan\n",
    "print(f\"\\nAUC Media sui task: {mean_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
