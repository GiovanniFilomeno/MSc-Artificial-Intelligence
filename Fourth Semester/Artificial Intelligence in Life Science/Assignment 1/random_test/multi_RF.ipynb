{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "from rdkit import RDLogger\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.ERROR)\n",
    "\n",
    "# Read dataset and map the values\n",
    "df = pd.read_csv(\"../data/data_train.csv\")\n",
    "task_cols = [f\"task{i}\" for i in range(1,12)]\n",
    "\n",
    "for c in task_cols:\n",
    "    df[c] = df[c].map({\n",
    "        -1: 0,\n",
    "        1: 1,\n",
    "        0: np.nan\n",
    "    })\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, MACCSkeys\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "\n",
    "def standardize_mol(mol):\n",
    "    # Base cleanup\n",
    "    mol = rdMolStandardize.Cleanup(mol)\n",
    "    # Only main fragment \n",
    "    lfc = rdMolStandardize.LargestFragmentChooser()\n",
    "    mol = lfc.choose(mol)\n",
    "    return mol\n",
    "\n",
    "def smiles_to_fp(smiles, \n",
    "                 nBits=1024, \n",
    "                 radius=2, \n",
    "                 use_MACCS=False, \n",
    "                 standardize=True):\n",
    "\n",
    "    # Converting SMILES to Mol\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        # if fails, zero array size nBits as dim or nBits + 166 with MACCS\n",
    "        maccs_size = 166 if use_MACCS else 0\n",
    "        return np.zeros(nBits + maccs_size, dtype=np.uint8)\n",
    "\n",
    "    # Standardization\n",
    "    if standardize:\n",
    "        mol = standardize_mol(mol)\n",
    "\n",
    "    # Generating fingerprint Morgan\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=nBits)\n",
    "    fp_morgan = fpgen.GetFingerprint(mol)\n",
    "    arr_morgan = np.zeros((nBits,), dtype=np.uint8)\n",
    "    DataStructs.ConvertToNumpyArray(fp_morgan, arr_morgan)\n",
    "\n",
    "    if not use_MACCS:\n",
    "        # Return only Morgan\n",
    "        return arr_morgan\n",
    "\n",
    "    # Otherwise, MACCS and concat\n",
    "    maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "    arr_maccs = np.zeros((maccs_fp.GetNumBits(),), dtype=np.uint8)\n",
    "    DataStructs.ConvertToNumpyArray(maccs_fp, arr_maccs)\n",
    "\n",
    "    # Concat\n",
    "    combined_fp = np.concatenate([arr_morgan, arr_maccs])\n",
    "    return combined_fp\n",
    "\n",
    "\n",
    "\n",
    "# Converting the columns\n",
    "X = np.array([smiles_to_fp(s, \n",
    "                           nBits=1024, \n",
    "                           radius=2, \n",
    "                           use_MACCS=True, \n",
    "                           standardize=True) \n",
    "              for s in df[\"smiles\"]],\n",
    "             dtype=np.float32)\n",
    "\n",
    "#Split train/test\n",
    "df_train, df_test, X_train, X_test = train_test_split(df, X, test_size=0.1, random_state=42)\n",
    "\n",
    "search_spaces = {\n",
    "    'n_estimators': Integer(5, 2500),  # Continuous range\n",
    "    'criterion': Categorical(['gini', 'entropy']), # Discrete values \n",
    "    'max_depth': Categorical([None, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35]), # Discrete values \n",
    "    'min_samples_split': Integer(2, 15), # Continuous range\n",
    "    'min_samples_leaf': Integer(1, 10),  # Continuous range\n",
    "    'max_features': Categorical(['sqrt', 'log2', 0.5, 0.7]), # Discrete values \n",
    "    'class_weight': Categorical([None, 'balanced']) # Discrete values \n",
    "}\n",
    "\n",
    "auc_list = []\n",
    "\n",
    "for i, task in enumerate(task_cols, start=1):\n",
    "    print(f\"\\n*** Tuning per {task} ***\")\n",
    "    # Selecting sample defined per training \n",
    "    train_mask = ~df_train[task].isna()\n",
    "    X_train_f = X_train[train_mask]\n",
    "    y_train_f = df_train.loc[train_mask, task].values.astype(int)\n",
    "\n",
    "    if len(y_train_f) == 0:\n",
    "        print(f\"No train sample found for {task}, skip.\")\n",
    "        continue\n",
    "\n",
    "    # Define RF\n",
    "    rf = RandomForestClassifier(random_state=0)  \n",
    "\n",
    "    n_iterations = 2000\n",
    "\n",
    "    grid_search = BayesSearchCV(\n",
    "        estimator=rf,\n",
    "        search_spaces=search_spaces, \n",
    "        n_iter=n_iterations,       \n",
    "        scoring='roc_auc',\n",
    "        cv=5,                     \n",
    "        n_jobs=-1,\n",
    "        random_state=42           \n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train_f, y_train_f)\n",
    "\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best params for {task}: {grid_search.best_params_}\")\n",
    "\n",
    "    # Saving Model\n",
    "    dump(best_model, f\"best_models/rf_task{i}.joblib\")\n",
    "    print(f\"Salvato: rf_task{i}.joblib\")\n",
    "\n",
    "    # Evaluation over test\n",
    "    test_mask = ~df_test[task].isna()\n",
    "    X_test_f = X_test[test_mask]\n",
    "    y_test_f = df_test.loc[test_mask, task].values.astype(int)\n",
    "\n",
    "    if len(y_test_f) == 0:\n",
    "        print(f\"No test sample found for {task}, skip.\")\n",
    "        continue\n",
    "\n",
    "    # Predicting prob\n",
    "    y_proba = best_model.predict_proba(X_test_f)[:, 1]  # output continuo\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "    precision = precision_score(y_test_f, y_pred, zero_division=0)\n",
    "    if len(np.unique(y_test_f)) == 2:\n",
    "        auc_val = roc_auc_score(y_test_f, y_proba)\n",
    "    else:\n",
    "        auc_val = np.nan\n",
    "\n",
    "    print(f\"{task} -> Precision={precision:.3f}, AUC={auc_val if not np.isnan(auc_val) else 'N/A'}\")\n",
    "    auc_list.append(auc_val)\n",
    "\n",
    "valid_aucs = [x for x in auc_list if not np.isnan(x)]\n",
    "mean_auc = np.mean(valid_aucs) if valid_aucs else np.nan\n",
    "print(f\"\\nAUC (AVG) over task: {mean_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmwTeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
